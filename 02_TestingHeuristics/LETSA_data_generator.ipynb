{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class & Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vertex:\n",
    "    def __init__(self, id_=\"\"):\n",
    "        self.id_ = id_\n",
    "        self.neighbours = {}\n",
    "    \n",
    "    def add_neighbour(self, nbr_vertex, weight=0):\n",
    "        self.neighbours[nbr_vertex] = weight\n",
    "    \n",
    "    def get_vertex_neighbours(self):\n",
    "        return self.neighbours.keys()\n",
    "    \n",
    "    def get_weight(self, neighbour):\n",
    "        if neighbour in self.neighbours.keys():\n",
    "            return self.neighbours[neighbour]\n",
    "        return None\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.id_ == other.id_\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.id_ < other.id_\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.id_)\n",
    "    \n",
    "    def __str__(self):\n",
    "        my_string = f\"Vertex {self.id_} is connected to: \"\n",
    "        my_neighbours = [vertex.id_ for vertex in self.get_vertex_neighbours()]\n",
    "        my_string += \", \".join(my_neighbours)\n",
    "        return my_string\n",
    "    \n",
    "class Graph:\n",
    "    def __init__(self):\n",
    "        self.vertices = {}\n",
    "        \n",
    "    def _create_vertex(self, id_):\n",
    "        return Vertex(id_)\n",
    "\n",
    "    def add_vertex(self, id_):\n",
    "        self.vertices[id_] = self._create_vertex(id_)\n",
    "\n",
    "    def get_vertex(self, id_):\n",
    "        return self.vertices.get(id_, None)\n",
    "        \n",
    "    def add_edge(self, start_v, end_v, weight=0):\n",
    "        if start_v not in self.vertices: \n",
    "            self.add_vertex(start_v)\n",
    "        if end_v not in self.vertices: \n",
    "            self.add_vertex(end_v)\n",
    "        v_start = self.vertices[start_v]\n",
    "        v_end = self.vertices[end_v]\n",
    "        v_start.add_neighbour(v_end)\n",
    "\n",
    "    def get_neighbours(self, id_):\n",
    "        vertex = self.get_vertex(id_)\n",
    "        if vertex:\n",
    "            return [neighbour.id_ for neighbour in vertex.get_vertex_neighbours()]\n",
    "        return []\n",
    " \n",
    "    def __contains__(self, id_):\n",
    "        return id_ in self.vertices\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter(self.vertices.values())\n",
    "\n",
    "    @property        \n",
    "    def num_vertices(self):\n",
    "        return len(self.vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_probabilities(D=0.5, n=10):\n",
    "#     \"\"\" \n",
    "#     Generates the probabilities of arc (i,j) existing for all i, j in n where i =/= j \n",
    "#     Probability values are generated based on (Hall & Posner, 2001)\n",
    "#     Inputs: \n",
    "#         - D          : float, value between 0 and 1 which sets the density of the graph\n",
    "#         - n          : int, number of nodes to be generated\n",
    "#     Output: \n",
    "#         Returns p_ij, a dictionary which stores the probability values using the following data structure: \n",
    "#             p_ij = { i: {j: p_ij} }\n",
    "#     \"\"\"\n",
    "#     p_ij = {}\n",
    "#     n = int(n)\n",
    "#     for i in range(1, n+1):\n",
    "#         p_ij[f\"J.{i}\"] = {}\n",
    "#         for j in range(1, n+1):\n",
    "#             if j != i: \n",
    "#                 p_ij[f\"J.{i}\"][f\"J.{j}\"] = D*(1-D)**(j-i-1) / (1 - D * (1 - (1-D)**(j-i-1) ))\n",
    "#     return p_ij \n",
    "import decimal\n",
    "\n",
    "\n",
    "decimal.getcontext().prec = 100\n",
    "\n",
    "def generate_probabilities(D=0.5, n=10):\n",
    "    \"\"\" \n",
    "    Generates the probabilities of arc (i,j) existing for all i, j in n where i =/= j \n",
    "    Probability values are generated based on (Hall & Posner, 2001)\n",
    "    Inputs: \n",
    "        - D          : float, value between 0 and 1 which sets the density of the graph\n",
    "        - n          : int, number of nodes to be generated\n",
    "    Output: \n",
    "        Returns p_ij, a dictionary which stores the probability values using the following data structure: \n",
    "            p_ij = { i: {j: p_ij} }\n",
    "    \"\"\"\n",
    "    p_ij = {}\n",
    "    n = int(n)\n",
    "    D = decimal.Decimal(D)\n",
    "    one = decimal.Decimal(1)\n",
    "    \n",
    "    for i in range(1, n + 1):\n",
    "        p_ij[f\"J.{i}\"] = {}\n",
    "        for j in range(1, n + 1):\n",
    "            if j != i:\n",
    "                exponent = decimal.Decimal(j - i - 1)\n",
    "                numerator = D * (one - D) ** exponent\n",
    "                denominator = one - D * (one - (one - D) ** exponent)\n",
    "                p_ij[f\"J.{i}\"][f\"J.{j}\"] = float(numerator / denominator)\n",
    "    return p_ij \n",
    "\n",
    "\n",
    "def generate_graph(n, p_ij, dict_graph={}):\n",
    "    \"\"\" \n",
    "    Generates a new graph with arcs and nodes that represent a BOM network. \n",
    "    The BOM network is generated based on a given set of probability values (Hall & Posner, 2001)\n",
    "    Inputs: \n",
    "        - n          : int, number of nodes in the graph \n",
    "        - p_ij       : dict, probability of arc (i,j) existing (p_ij = { i: {j: p_ij}})\n",
    "        - dict_graph : dict, alternative method to store graph information using adjacency matrix \n",
    "    Output: \n",
    "        - g          : graph object containing node and edges information\n",
    "        - dict_graph : no output, but dict_graph is processed in place \n",
    "    Specific Features:\n",
    "        - The graph generated does not contain self-connecting cycles\n",
    "    \"\"\"\n",
    "\n",
    "    g = Graph()\n",
    "    edges = []\n",
    "\n",
    "    for i in range(1, n+1):\n",
    "        dict_graph[f\"J.{i}\"] = []\n",
    "        for j in range(i + 1, n + 1):\n",
    "            dict_graph[f\"J.{j}\"] = []\n",
    "            if p_ij[f\"J.{i}\"][f\"J.{j}\"] <= random.random():\n",
    "                edges.append((f\"J.{i}\", f\"J.{j}\"))\n",
    "\n",
    "    for u, v in edges:\n",
    "        u, v = str(u), str(v)\n",
    "        if g.get_neighbours(u):\n",
    "            continue  # Skip if u already has a successor\n",
    "        if u < v:\n",
    "            if not any(g.get_vertex(str(w)) for w in g.get_neighbours(v) if g.get_vertex(u) in g.get_neighbours(w)):\n",
    "                g.add_edge(u, v)\n",
    "                dict_graph[u].append(v)\n",
    "        else:\n",
    "            if not any(g.get_vertex(str(w)) for w in g.get_neighbours(u) if g.get_vertex(v) in g.get_neighbours(w)):\n",
    "                g.add_edge(u, v)\n",
    "                dict_graph[u].append(v)\n",
    "    return g\n",
    "\n",
    "\n",
    "\n",
    "def visualize_graph(graph, figure_size=(8, 6), font_type=\"Century Gothic\", font_size=15, node_size=1500, node_color='lightblue', edge_color='black', alpha=1, folder_path=None, file_name=None):\n",
    "    \"\"\" \n",
    "    Generates a visualization for a graph object. The visualization is made in such a way that: \n",
    "        (1) Nodes with no immediate predecessors are placed to the left of the image\n",
    "        (2) Nodes with no immediate successors are placed to the right of the image \n",
    "        (3) All other remaining nodes are placed in between. \n",
    "    Inputs (Required): \n",
    "        - graph         : graph object, containing the nodes and edges to be visualized\n",
    "    Inputs (Optional):\n",
    "        - figure_size   : tuple, sets the preferred size of the image\n",
    "        - font_type     : str, sets the font family\n",
    "        - font_size     : float, sets the size of the font\n",
    "        - node_size     : float, sets the size of the nodes\n",
    "        - node_color    : str, sets the color of the nodes\n",
    "        - edge_color    : str, sets the color of the edges\n",
    "        - edge_alpha    : float, value between 0 and 1 which sets the density of the edges\n",
    "    Output: \n",
    "        - Visualization of the graph using plt.show()\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    for vertex in graph:\n",
    "        G.add_node(vertex.id_)\n",
    "        for neighbour in vertex.get_vertex_neighbours():\n",
    "            G.add_edge(vertex.id_, neighbour.id_)\n",
    "    \n",
    "    # Create custom positions for nodes\n",
    "    pos = {}\n",
    "    nodes_without_predecessors = [node for node in G.nodes if G.in_degree(node) == 0]\n",
    "    nodes_without_successors = [node for node in G.nodes if G.out_degree(node) == 0]\n",
    "    other_nodes = [node for node in G.nodes if node not in nodes_without_predecessors and node not in nodes_without_successors]\n",
    "    \n",
    "    # Assign layers\n",
    "    layers = {node: 0 for node in nodes_without_predecessors}\n",
    "    for node in other_nodes:\n",
    "        predecessors = G.predecessors(node)\n",
    "        layers[node] = max(layers[pred] + 1 for pred in predecessors if pred in layers)\n",
    "    for node in nodes_without_successors:\n",
    "        predecessors = G.predecessors(node)\n",
    "        layers[node] = max(layers[pred] + 1 for pred in predecessors if pred in layers)\n",
    "    \n",
    "    # Add subset attribute to nodes\n",
    "    for node, layer in layers.items():\n",
    "        G.nodes[node]['subset'] = layer\n",
    "    \n",
    "    # Assign positions using multipartite_layout\n",
    "    pos = nx.multipartite_layout(G, subset_key='subset')\n",
    "    \n",
    "    # Draw the graph with custom positions\n",
    "    plt.figure(figsize=figure_size)\n",
    "    nx.draw(G, pos, with_labels=True, font_family=font_type, font_weight='bold', font_size=font_size,\n",
    "            node_color=node_color, node_size=node_size,  \n",
    "            edge_color=edge_color, alpha=alpha)\n",
    "    if folder_path and file_name:\n",
    "        plt.savefig(f\"{folder_path}//{file_name}.png\")\n",
    "        # plt.show()\n",
    "        plt.close()\n",
    "    # else:\n",
    "    #     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Machine Speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogarithmicDistribution:\n",
    "    def __init__(self, p):\n",
    "        if not (0 < p < 1):\n",
    "            raise ValueError(\"Parameter p must be between 0 and 1.\")\n",
    "        self.p = p\n",
    "\n",
    "    def pmf(self, k):\n",
    "        \"\"\"Probability mass function of the logarithmic distribution.\"\"\"\n",
    "        if k < 1:\n",
    "            return 0\n",
    "        return -self.p**k / (k * np.log(1 - self.p))\n",
    "\n",
    "    def sample(self, size=1):\n",
    "        \"\"\"Generate random samples from the logarithmic distribution.\"\"\"\n",
    "        # Using inverse transform sampling\n",
    "        samples = []\n",
    "        for _ in range(size):\n",
    "            u = np.random.uniform(0, 1)\n",
    "            k = 1\n",
    "            sum_pmf = self.pmf(k)\n",
    "            while u > sum_pmf:\n",
    "                k += 1\n",
    "                sum_pmf += self.pmf(k)\n",
    "            samples.append(k)\n",
    "        return np.array(samples)\n",
    "\n",
    "    def plot_pmf(self, max_k=20):\n",
    "        \"\"\"Plot the probability mass function.\"\"\"\n",
    "        ks = np.arange(1, max_k + 1)\n",
    "        pmf_values = [self.pmf(k) for k in ks]\n",
    "        plt.stem(ks, pmf_values, use_line_collection=True)\n",
    "        plt.xlabel('k')\n",
    "        plt.ylabel('P(X=k)')\n",
    "        plt.title('Logarithmic Distribution PMF')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(data, bins=10, title='Histogram', xlabel='Value', ylabel='Frequency'):\n",
    "    \"\"\"\n",
    "    Plots a histogram of the given data.\n",
    "\n",
    "    Parameters:\n",
    "    - data: array-like, the input array of numbers.\n",
    "    - bins: int, the number of bins for the histogram.\n",
    "    - title: str, the title of the plot.\n",
    "    - xlabel: str, the label for the x-axis.\n",
    "    - ylabel: str, the label for the y-axis.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(data, bins=bins, edgecolor='black', alpha=0.7)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Machine Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_transition_matrix(M, bottleneck_machine=None, bottleneck_probability=0.3):\n",
    "    \"\"\"\n",
    "    Generate a transition matrix for machine assignments.\n",
    "    Inputs:\n",
    "        - M                         : int, number of machines\n",
    "        - bottleneck_machine        : int or None, index of the bottleneck machine (0-indexed)\n",
    "        - bottleneck_probability    : float, probability that the bottleneck machine will be chosen\n",
    "    Output:\n",
    "        - transition_matrix         : numpy array of shape (M, M) containing transition probabilities\n",
    "    \"\"\"\n",
    "    transition_matrix = np.ones((M, M))\n",
    "    if bottleneck_machine is not None:\n",
    "        bottleneck_machine -= 1  # Convert to 0-indexed\n",
    "        transition_matrix[:, bottleneck_machine] = bottleneck_probability\n",
    "        other_probability = (1 - bottleneck_probability) / (M - 1)\n",
    "        for i in range(M):\n",
    "            if i != bottleneck_machine:\n",
    "                transition_matrix[:, i] = other_probability\n",
    "    transition_matrix = transition_matrix / transition_matrix.sum(axis=1)[:, np.newaxis]\n",
    "    return transition_matrix\n",
    "\n",
    "def assign_machines(df, M, bottleneck_machine=None, bottleneck_probability=0.3):\n",
    "    \"\"\"\n",
    "    Assign machines to operations based on a transition probability matrix.\n",
    "    Inputs:\n",
    "        - df                        : DataFrame, containing the operations and their predecessors\n",
    "        - M                         : int, number of machines\n",
    "        - bottleneck_machine        : int or None, index of the bottleneck machine (0-indexed)\n",
    "        - bottleneck_probability    : float, probability that the bottleneck machine will be chosen\n",
    "    Output:\n",
    "        - df                        : DataFrame, with an additional column \"machine\" assigned\n",
    "    \"\"\"\n",
    "    transition_matrix = generate_transition_matrix(M, bottleneck_machine, bottleneck_probability)\n",
    "    current_machine = random.randint(0, M - 1)  # Start with a random machine (0-indexed)\n",
    "\n",
    "    machine_assignments = []\n",
    "    for _ in range(len(df)):\n",
    "        next_machine_idx = np.random.choice(M, p=transition_matrix[current_machine])\n",
    "        next_machine = f\"M{1 + np.random.choice(M, p=transition_matrix[current_machine])}\"\n",
    "        machine_assignments.append(next_machine) \n",
    "        current_machine = next_machine_idx\n",
    "    \n",
    "    df['machine'] = machine_assignments\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(n, M, D, p, dd=(0,50), folder_path=None, file_name=None, bottleneck_machine=None, display_graph=False):\n",
    "    # ===========================\n",
    "    # BOM PRECEDENCE NETWORK \n",
    "    # ===========================\n",
    "    df = pd.DataFrame({\n",
    "        \"operation\": [None] * n,\n",
    "        \"predecessor_operations\": [None] * n\n",
    "    })\n",
    "    while True:\n",
    "        p_ij = generate_probabilities(D=D, n=n)\n",
    "        dict_graph = {}\n",
    "        g = generate_graph(n, p_ij, dict_graph)\n",
    "        reversed_graph = {f\"J.{i}\": [] for i in range(1, len(dict_graph))} # graph reversed to ease next part\n",
    "        for predecessor, successors in dict_graph.items():\n",
    "            for successor in successors:\n",
    "                reversed_graph.setdefault(successor, []).append(predecessor)\n",
    "        i = 0\n",
    "        for successor in reversed_graph.keys():\n",
    "            df.at[i, \"operation\"] = successor\n",
    "            df.at[i, \"predecessor_operations\"] = reversed_graph[successor]\n",
    "            i += 1\n",
    "        if not df['operation'].isna().any(): \n",
    "            # check if all operations have been included\n",
    "            # there is a chance that some operations are not included, due to p_ij \n",
    "            break\n",
    "    # Visualization\n",
    "    if display_graph:\n",
    "        fig_size = (24, 18) if n >= 30 else (12, 9) if n > 15 else (8, 6) \n",
    "        visualize_graph(g, figure_size=fig_size, folder_path=folder_path, file_name=file_name)\n",
    "\n",
    "    # ===========================\n",
    "    # OPERATION PROCESSING TIMES\n",
    "    # ===========================\n",
    "    log_dist = LogarithmicDistribution(p)\n",
    "    df['processing_time'] = log_dist.sample(n)\n",
    "\n",
    "    # ===========================\n",
    "    # MACHINE ROUTING\n",
    "    # ===========================\n",
    "    df = assign_machines(df, M, bottleneck_machine, bottleneck_probability=0.7)\n",
    "\n",
    "    # ===========================\n",
    "    # WORKCENTER INFORMATION\n",
    "    # ===========================\n",
    "    df['workcenter'] = [f\"WC{random.randint(1, 3)}\" for _ in range(n)]\n",
    "\n",
    "    # ===========================\n",
    "    # END_PRODUCT &  DUE DATES \n",
    "    # ===========================\n",
    "    def flatten(test_list):\n",
    "        if isinstance(test_list, list):\n",
    "            temp = []\n",
    "            for ele in test_list:\n",
    "                temp.extend(flatten(ele))\n",
    "            return temp\n",
    "        else:\n",
    "            return [test_list]\n",
    "    predecessor_operations = flatten(df['predecessor_operations'].tolist())\n",
    "    unique_operations = list(df['operation'].unique())\n",
    "    end_products = [item for item in unique_operations if item not in predecessor_operations]\n",
    "    df['due_date'] = None    \n",
    "    df['end_product'] = 0   \n",
    "    for end_product in end_products: \n",
    "        df.at[int(end_product[2:])-1, 'due_date'] = random.randint(dd[0], dd[1]) \n",
    "        df.at[int(end_product[2:])-1, 'end_product'] = 1\n",
    "        # the above code assumes each operation is named \"J.xxx\" where xxx is the operation number \n",
    "\n",
    "\n",
    "    return df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def flatten(test_list):\n",
    "#     if isinstance(test_list, list):\n",
    "#         temp = []\n",
    "#         for ele in test_list:\n",
    "#             temp.extend(flatten(ele))\n",
    "#         return temp\n",
    "#     else:\n",
    "#         return [test_list]\n",
    "\n",
    "# mylist = flatten(df['predecessors'].tolist())\n",
    "# unique_operations = list(df['operation'].unique())\n",
    "# end_products = [item for item in unique_operations if item not in mylist]\n",
    "# # print(mylist)\n",
    "# # print(unique_operations)\n",
    "# print(end_products)\n",
    "\n",
    "\n",
    "# df['due_date'] = None\n",
    "# for end_product in end_products: \n",
    "#     df.at[int(end_product)-1, 'due_date'] = random.randint(80,100)\n",
    "\n",
    "# # display(df.head())\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>operation</th>\n",
       "      <th>predecessor_operations</th>\n",
       "      <th>processing_time</th>\n",
       "      <th>machine</th>\n",
       "      <th>workcenter</th>\n",
       "      <th>due_date</th>\n",
       "      <th>end_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J.1</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>M14</td>\n",
       "      <td>WC1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J.2</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>M18</td>\n",
       "      <td>WC1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J.3</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>M18</td>\n",
       "      <td>WC1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>J.4</td>\n",
       "      <td>[J.1]</td>\n",
       "      <td>3</td>\n",
       "      <td>M19</td>\n",
       "      <td>WC3</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J.5</td>\n",
       "      <td>[J.2, J.3]</td>\n",
       "      <td>1</td>\n",
       "      <td>M4</td>\n",
       "      <td>WC2</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>J.96</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>M20</td>\n",
       "      <td>WC1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>J.97</td>\n",
       "      <td>[J.94, J.95]</td>\n",
       "      <td>1</td>\n",
       "      <td>M19</td>\n",
       "      <td>WC2</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>J.98</td>\n",
       "      <td>[J.96]</td>\n",
       "      <td>1</td>\n",
       "      <td>M19</td>\n",
       "      <td>WC3</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>J.99</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>M18</td>\n",
       "      <td>WC1</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>J.100</td>\n",
       "      <td>[J.97, J.98]</td>\n",
       "      <td>1</td>\n",
       "      <td>M6</td>\n",
       "      <td>WC3</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   operation predecessor_operations  processing_time machine workcenter  \\\n",
       "0        J.1                     []                1     M14        WC1   \n",
       "1        J.2                     []                1     M18        WC1   \n",
       "2        J.3                     []                1     M18        WC1   \n",
       "3        J.4                  [J.1]                3     M19        WC3   \n",
       "4        J.5             [J.2, J.3]                1      M4        WC2   \n",
       "..       ...                    ...              ...     ...        ...   \n",
       "95      J.96                     []                1     M20        WC1   \n",
       "96      J.97           [J.94, J.95]                1     M19        WC2   \n",
       "97      J.98                 [J.96]                1     M19        WC3   \n",
       "98      J.99                     []                1     M18        WC1   \n",
       "99     J.100           [J.97, J.98]                1      M6        WC3   \n",
       "\n",
       "   due_date  end_product  \n",
       "0      None            0  \n",
       "1      None            0  \n",
       "2      None            0  \n",
       "3      None            0  \n",
       "4      None            0  \n",
       "..      ...          ...  \n",
       "95     None            0  \n",
       "96     None            0  \n",
       "97     None            0  \n",
       "98       86            1  \n",
       "99       99            1  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Sample Implementation\n",
    "random.seed(42)\n",
    "D = 0.9\n",
    "n = 100\n",
    "\n",
    "p_ij = generate_probabilities(D=D, n=n)\n",
    "df = generate_dataset(\n",
    "    n=n, \n",
    "    M=20, \n",
    "    D=D, \n",
    "    p=0.25,\n",
    "    dd=(80,100), \n",
    "    display_graph=False\n",
    ")\n",
    "\n",
    "display(df)\n",
    "print(df['operation'].isna().any())\n",
    "\n",
    "# import matplotlib.pyplot as plt \n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(df['processing_time'], edgecolor='black', bins=100)\n",
    "# plt.title('Histogram of Variable')\n",
    "# plt.xlabel('Value')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# mylist = df['processing_time'].unique().tolist()\n",
    "# mylist.sort()\n",
    "# print(mylist)\n",
    "# for time in mylist: \n",
    "#     print(time, len(df.loc[(df['processing_time']==time)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "small scale operation\n",
    "    n = 15 to 30\n",
    "    p = 0.15 to 0.95\n",
    "    D = 0.1, 0.25, 0.5, 0.75, 0.9\n",
    "\n",
    "mid scale operation\n",
    "    n = 50 \n",
    "    p = 0.15 to 0.95\n",
    "    D = 0.1, 0.25, 0.5, 0.75, 0.9\n",
    "\n",
    "big scale operation \n",
    "    n = 100 to 200 or more \n",
    "    p = 0.15 to 0.95\n",
    "    D = 0.1, 0.25, 0.5, 0.75, 0.9\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "list_n = [200,100,50,30,15]\n",
    "list_p = [0.15, 0.4, 0.75, 0.95]\n",
    "list_M = [1, 2, 5]\n",
    "list_D = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "dict_dd = {\n",
    "    200: [(2000,2500), (2000,3000), (2000,5000)],  \n",
    "    100: [(1000,1500), (1000,2000), (1000,4000)],  \n",
    "    50: [(500,1000), (500,1000), (500,1250)],  \n",
    "    30: [(500,750), (500,1000), (500,1250)],  \n",
    "    15: [(250,500), (250,750), (250,1000)],  \n",
    "} \n",
    "\n",
    "for n in list_n: \n",
    "    display_switch = False if n >= 50 else True\n",
    "    for M in list_M: \n",
    "        folder_path = f\"TestCases\"\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "        for D in list_D:\n",
    "            for p in list_p:\n",
    "                for dd in dict_dd[n]:\n",
    "                    filename = f\"{n}operations_{M}machines_{p}p_{D}D_({dd[0]},{dd[1]})dd\"\n",
    "                    df = generate_dataset(n, M, D, p, dd=dd, folder_path=folder_path, file_name=filename, bottleneck_machine=None, display_graph=display_switch)\n",
    "                    df.to_csv(f\"{folder_path}//{filename}.csv\", index=False)\n",
    "\n",
    "                    if M > 1:                 \n",
    "                        df = generate_dataset(n, M, D, p, dd=dd, folder_path=folder_path, file_name=filename, bottleneck_machine=random.randint(1, M), display_graph=display_switch)\n",
    "                        filename = f\"{n}operations_{M}machines_{p}p_{D}D_({dd[0]},{dd[1]})dd_bottleneck\"\n",
    "                        df.to_csv(f\"{folder_path}//{filename}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
