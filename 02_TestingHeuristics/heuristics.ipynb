{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# LETSA\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "import os\n",
    "import time\n",
    "import ast\n",
    "\n",
    "# EDD\n",
    "import heapq\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# SA\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WorkCenter:\n",
    "    def __init__(self, id, dict_machines={}):\n",
    "        self.id = str(id)\n",
    "        self.machines = dict_machines\n",
    "        # dict_machines = {'M1': [ [], [], [] ] }\n",
    "\n",
    "class Operation:\n",
    "    def __init__(self, id, processing_time, workcenter, machine, due_date=None, successors=None, predecessors=None):\n",
    "        self.id = str(id)\n",
    "        self.successor = str(successors) if successors else None\n",
    "        self.predecessors = predecessors if predecessors else []\n",
    "        self.workcenter = str(workcenter)\n",
    "        self.machine = str(machine)\n",
    "        self.scheduled_machine_idx = None\n",
    "        self.processing_time = processing_time\n",
    "        self.start_time = None\n",
    "        self.end_time = None\n",
    "        self.due_date = None if due_date != due_date else due_date\n",
    "        self.scheduled = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LETSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_operations(df):\n",
    "    \"\"\"\n",
    "    Loads the operation information from the df_BOM\n",
    "    Initializes an Operation object for each of the operation and stores it in the operations dictionary\n",
    "    Inputs: \n",
    "        - df            : a dataframe consisting the BOM information  \n",
    "        - filename      : \n",
    "    Outputs:\n",
    "        - operations    : \n",
    "    \"\"\"\n",
    "\n",
    "    operations = {}\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        op = Operation(\n",
    "            id=str(row['operation']),\n",
    "            processing_time=row['processing_time'],\n",
    "            workcenter=row['workcenter'],\n",
    "            machine=row['machine'],\n",
    "            due_date=row['due_date'],\n",
    "            predecessors=row['predecessor_operations']\n",
    "        )\n",
    "        operations[op.id] = op\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        current_op_id = row['operation']\n",
    "        predecessor_ops = row['predecessor_operations']\n",
    "        for predecessor in predecessor_ops:\n",
    "            operations[predecessor].successor = current_op_id\n",
    "    \n",
    "    return operations\n",
    "\n",
    "def load_factory(df_machine):\n",
    "    factory = {}\n",
    "    for idx, row in df_machine.iterrows():\n",
    "        workcenter = row['workcenter']\n",
    "        dict_machines = {}\n",
    "        for machine in (df_machine.columns[1:]): \n",
    "            dict_machines[machine] = [[] for _ in range(row[machine])]\n",
    "        # factory.append(WorkCenter(workcenter, dict_machines=dict_machines))\n",
    "        factory[workcenter] = WorkCenter(workcenter, dict_machines=dict_machines)\n",
    "    return factory \n",
    "\n",
    "def calculate_makespan(factory):\n",
    "    list_schedules = []\n",
    "    for workcenter_key in factory:\n",
    "        for _, machine_schedule in factory[workcenter_key].machines.items():\n",
    "            flattened_schedule = [item for sublist in machine_schedule for item in sublist]\n",
    "            list_schedules += flattened_schedule\n",
    "\n",
    "    _max = max(list_schedules, key=lambda x: x[1])[1]\n",
    "    _min = min(list_schedules, key=lambda x: x[0])[0]\n",
    "\n",
    "    return _max - _min\n",
    "\n",
    "def format_schedule(scheduled_operations, factory):\n",
    "    df_schedule = pd.DataFrame()\n",
    "    for i, operation in enumerate(scheduled_operations): \n",
    "        df_schedule.at[i, \"WorkCenter\"] = operation.workcenter\n",
    "        df_schedule.at[i, \"Machine\"] = operation.machine\n",
    "        df_schedule.at[i, \"MachineIdx\"] = operation.scheduled_machine_idx+1\n",
    "        df_schedule.at[i, \"Operation\"] = operation.id\n",
    "        df_schedule.at[i, \"Start\"] = operation.start_time\n",
    "        df_schedule.at[i, \"End\"] = operation.start_time + operation.processing_time\n",
    "    df_schedule['PercentCompletion'] = 100  \n",
    "\n",
    "    for workcenter_key in factory: \n",
    "        workcenter = factory[workcenter_key]\n",
    "        for machine_type, machine_schedules in workcenter.machines.items():\n",
    "            for machine_idx, machine_schedule in enumerate(machine_schedules): \n",
    "                if len(machine_schedule) == 0:\n",
    "                    new_row = {\n",
    "                        \"WorkCenter\": workcenter.id,\n",
    "                        \"Machine\": machine_type,\n",
    "                        \"MachineIdx\": machine_idx,\n",
    "                        \"Operation\": None,\n",
    "                        \"Start\": None,\n",
    "                        \"End\": None,\n",
    "                        \"PercentCompletion\": None\n",
    "                    }\n",
    "                    new_row_df = pd.DataFrame([new_row])\n",
    "                    df_schedule = pd.concat([df_schedule, new_row_df], ignore_index=True)\n",
    "\n",
    "    return df_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LETSA_find_critical_path(operations, feasible_operations): \n",
    "    \"\"\"\n",
    "    Finds the critical path among the feasible operations.\n",
    "    Inputs:\n",
    "        - operations                    : dictionary {operation_id: Operation()}, a dictionary of all operations\n",
    "        - feasible_operations           : list[operation_id],  a list of operation IDs that are currently feasible\n",
    "    Output:\n",
    "        - critical_path, critical_length\n",
    "    \"\"\"\n",
    "\n",
    "    def dfs(operations, current_op_id, path, path_length, all_paths):\n",
    "        \"\"\" \n",
    "        Performs recursive DFS on the operation network. \n",
    "        Inputs: \n",
    "            - operations                : dictionary {operation_id: Operation()}, dictionary of all operations \n",
    "            - current_op_id             : str, the ID of the node at which the DFS is performed\n",
    "            - path                      : list, to keep track of current path\n",
    "            - path_length               : float, to keep track of current path length\n",
    "            - all_paths                 : list, to keep track of all possible paths \n",
    "        Output: \n",
    "            - None, perform in place\n",
    "        \"\"\"\n",
    "\n",
    "        path.append(current_op_id)\n",
    "        path_length += operations[current_op_id].processing_time\n",
    "        \n",
    "        if not operations[current_op_id].predecessors:\n",
    "            all_paths.append((list(path), path_length))\n",
    "        else:\n",
    "            for pred in operations[current_op_id].predecessors:\n",
    "                dfs(operations, pred, path, path_length, all_paths)\n",
    "        \n",
    "        path.pop()\n",
    "        path_length -= operations[current_op_id].processing_time\n",
    "\n",
    "    def find_all_paths(operations, feasible_operations):\n",
    "        \"\"\"\n",
    "        Calls DFS on all the feasible operations. \n",
    "        Inputs: \n",
    "            - operations                : dictionary {operation_id: Operation()}, dictionary of all operations \n",
    "            - feasible_operations       : list [operation_id], list of all feasible operations to perform DFS on \n",
    "        \"\"\"\n",
    "\n",
    "        all_paths = []\n",
    "        for op_id in feasible_operations:\n",
    "            dfs(operations, op_id, [], 0, all_paths)\n",
    "        return all_paths\n",
    "\n",
    "    all_paths = find_all_paths(operations, feasible_operations)\n",
    "    # print(\"     printing all paths\")\n",
    "    # for path in all_paths: \n",
    "        # print(path[0], path[1])\n",
    "    critical_path, critical_length = max(all_paths, key=lambda x:x[1])\n",
    "\n",
    "    return critical_path, critical_length\n",
    "\n",
    "def LETSA_schedule_operations(operations, factory):\n",
    "    \"\"\"\n",
    "    Solves the assembly scheduling problem (ASP) using the Longest End Time Scheduling Algorithm (LETSA).\n",
    "    Inputs:\n",
    "        - operations            : dictionary {operation_id: Operation()}, a dictionary of all operations.\n",
    "        - factory               : list [WorkCenter()], a list of WorkCenter objects, containing machine information and availability\n",
    "    Output:\n",
    "        - scheduled_operations  : list [Operation()], a list of Operation objects with start and end time schedules.\n",
    "    \"\"\"\n",
    "\n",
    "    scheduled_operations = []\n",
    "    # [[Step 4]]\n",
    "    i = 1\n",
    "    while True:\n",
    "        # print(f\"Iteration {i}\")\n",
    "        # ================================================================================================================\n",
    "        #  [[4.0]] Feasible operations = every operation that is \n",
    "        #                               (1) not scheduled, and \n",
    "        #                               (2) has all successors scheduled, OR does not have any successors\n",
    "        # ================================================================================================================\n",
    "        feasible_operations = [op_id for op_id, op in operations.items() if ((not op.scheduled) and (op.successor==None or operations[op.successor].scheduled))]\n",
    "        # print(f\"feasible operations: {feasible_operations}\")\n",
    "        if not feasible_operations:\n",
    "            break # terminate if all operations have been scheduled\n",
    "\n",
    "        # ===================================================================\n",
    "        #  [[4.1 - 4.3]] Compute critical path only for feasible operations\n",
    "        # ===================================================================\n",
    "        critical_path, length = LETSA_find_critical_path(operations, feasible_operations)\n",
    "        selected_operation_id = critical_path[0]\n",
    "        selected_operation = operations[selected_operation_id]\n",
    "        # print(f\"critical path: {critical_path}, length: {length}\")\n",
    "        # print(f\"selected operation: {selected_operation_id}\")\n",
    "\n",
    "        # =====================================================================\n",
    "        # [[4.4]] Set completion/end time of the selected operation as\n",
    "        #         (ii) the start time of the successor, if a successor exists\n",
    "        #         (ii) the project deadline, otherwise \n",
    "        # =====================================================================\n",
    "        if selected_operation.successor: \n",
    "            # if the operation has a successor \n",
    "            # then the tentative end time is the start time of the successor\n",
    "            successor_id = selected_operation.successor\n",
    "            tentative_completion_time = operations[successor_id].start_time\n",
    "        else: \n",
    "            # else, the operation is an end product and its tentative completion time must be its own deadline\n",
    "            tentative_completion_time = selected_operation.due_date\n",
    "\n",
    "        # ============================================================================\n",
    "        #   [[4.5]] For each identical machine incuded in the required work-center \n",
    "        # ============================================================================\n",
    "        def check_availability(time, machine_usage): \n",
    "            \"\"\"\n",
    "            Returns True if the time interval does not overlap with any intervals in machine_usage, False otherwise.\n",
    "                time            : (start, end)\n",
    "                machine_usage   : list of tuples [(start1, end1), (start2, end2), ...]\n",
    "            \"\"\"\n",
    "            start, end = time\n",
    "            for interval in machine_usage:\n",
    "                interval_start, interval_end = interval\n",
    "                if not (end <= interval_start or start >= interval_end):\n",
    "                    return False\n",
    "            return True\n",
    "\n",
    "        def find_latest_start_time(completion_time, processing_time, machine_usage):\n",
    "            \"\"\"\n",
    "            completion_time : float\n",
    "            processing_time : float\n",
    "            machine_usage   : list of tuples [(start1, end1), (start2, end2), ...]\n",
    "            \n",
    "            Returns the latest possible start time such that the job can be completed\n",
    "            before the completion time and does not overlap with any intervals in machine_usage.\n",
    "            \"\"\"\n",
    "            latest_start_time = completion_time - processing_time\n",
    "\n",
    "            # Sort the machine usage intervals by their start times\n",
    "            machine_usage = sorted(machine_usage, key=lambda x: x[0])\n",
    "            \n",
    "            # Iterate over the machine usage intervals in reverse order\n",
    "            for interval in reversed(machine_usage):\n",
    "                interval_start, interval_end = interval\n",
    "                \n",
    "                # Check if there is a gap between the intervals where the job can fit\n",
    "                if interval_end <= latest_start_time:\n",
    "                    if check_availability((latest_start_time, latest_start_time + processing_time), machine_usage):\n",
    "                        return latest_start_time\n",
    "                latest_start_time = min(latest_start_time, interval_start - processing_time)\n",
    "            \n",
    "            # Check if the latest possible start time is valid\n",
    "            if check_availability((latest_start_time, latest_start_time + processing_time), machine_usage):\n",
    "                return latest_start_time\n",
    "            \n",
    "            return None\n",
    "\n",
    "        current_workcenter_id = str(selected_operation.workcenter)\n",
    "        # print(type(current_workcenter_id))\n",
    "        # print(factory)\n",
    "        current_workcenter = factory[current_workcenter_id]             # WorkCenter object \n",
    "        machine_type = str(selected_operation.machine)                  # machine id of required machine\n",
    "        possible_machines = current_workcenter.machines[machine_type]   # [[], [], []]\n",
    "\n",
    "        processing_time = selected_operation.processing_time\n",
    "        tentative_start_time = tentative_completion_time - processing_time\n",
    "        possible_start_times = []\n",
    "        for machine_idx, machine_schedule in enumerate(possible_machines):\n",
    "            # print(machine_idx, machine_schedule)\n",
    "            # if not machine_schedule:  # If machine schedule is empty, then machine is immediately useable\n",
    "            #     latest_available_start_time = tentative_completion_time - selected_operation.processing_time\n",
    "            if check_availability((tentative_start_time, tentative_completion_time), machine_schedule) :\n",
    "                start_time, end_time = tentative_start_time, tentative_completion_time\n",
    "            else: \n",
    "                start_time = find_latest_start_time(tentative_completion_time, processing_time, machine_schedule) \n",
    "                end_time = start_time + processing_time\n",
    "            possible_start_times.append((machine_idx, start_time, end_time))\n",
    "            # print(start_time, end_time)\n",
    "\n",
    "        # ============================================================================\n",
    "        #   [[4.6]] Select a machine to schedule operation Jc  \n",
    "        # ============================================================================\n",
    "        selected_machine, finalized_start_time, finalized_end_time = max(possible_start_times, key=lambda x:x[1]) \n",
    "        current_workcenter.machines[machine_type][machine_idx].append((finalized_start_time, finalized_end_time))\n",
    "\n",
    "        # ============================================================================\n",
    "        #   [[4.7]] Delete operation Jc from the network\n",
    "        #   [[4.8]] Add all eligible operations into the list of feasible operations     \n",
    "        # ============================================================================\n",
    "        selected_operation.start_time = start_time\n",
    "        selected_operation.end_time = end_time\n",
    "        selected_operation.scheduled = True\n",
    "        selected_operation.scheduled_machine_idx = selected_machine\n",
    "        scheduled_operations.append(selected_operation)\n",
    "\n",
    "        i += 1 \n",
    "        # print()\n",
    "        \n",
    "    return scheduled_operations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EDD_find_earliest_start_time(machine_usage, minimum_start_time, processing_time, print_button=False):\n",
    "    \"\"\"\n",
    "    Finds the earliest start time on the given machine that avoids overlapping with existing jobs.\n",
    "    Inputs: \n",
    "        - machine_usage         : [(3,4), (5,6)] \n",
    "        - desired_start_time    : start time must not be earlier than this \n",
    "        - processing_time       : operation processing time \n",
    "    \"\"\"\n",
    "   \n",
    "    machine_usage.sort()\n",
    "    start_time = None\n",
    "\n",
    "    if len(machine_usage) == 0:\n",
    "        start_time = minimum_start_time \n",
    "        # if print_button:\n",
    "        #     print(\"A\")\n",
    "        return start_time\n",
    "\n",
    "    for i in range(len(machine_usage)-1): \n",
    "        # if print_button: \n",
    "        #     print(\"B\")\n",
    "        tentative_start = machine_usage[i][1]\n",
    "        tentative_end = machine_usage[i+1][0]\n",
    "        if (tentative_end - tentative_start >= processing_time) and (tentative_start >= minimum_start_time):\n",
    "            start_time = tentative_start \n",
    "            return start_time \n",
    "    \n",
    "    if start_time is None: \n",
    "        # if print_button: \n",
    "        #     print(\"C\")\n",
    "        #     print(machine_usage)\n",
    "        start_time = machine_usage[len(machine_usage)-1][1]\n",
    "        if start_time < minimum_start_time:\n",
    "            start_time = minimum_start_time\n",
    "        return start_time\n",
    "\n",
    "def EDD_schedule_operations(operations, factory):\n",
    "    def check_availability(start_time, processing_time, machine_usage):\n",
    "        \"\"\"\n",
    "        Returns True if the time interval does not overlap with any intervals in machine_usage, False otherwise.\n",
    "        \"\"\"\n",
    "        end_time = start_time + processing_time\n",
    "        for interval in machine_usage:\n",
    "            if len(interval) != 2:\n",
    "                raise ValueError(\"Machine usage interval does not contain exactly 2 values\")\n",
    "            interval_start, interval_end = interval\n",
    "            if not (end_time <= interval_start or start_time >= interval_end):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    # =====================\n",
    "    #   Initialize Queue \n",
    "    # =====================\n",
    "    scheduled_operations, Q = [], []\n",
    "    unscheduled_dependencies = {op_id: len(op.predecessors) for op_id, op in operations.items()}\n",
    "    # print(f\"Unscheduled dependencies: {unscheduled_dependencies}\")\n",
    "\n",
    "    for op_id, count in unscheduled_dependencies.items():\n",
    "        if count == 0:\n",
    "            heapq.heappush(Q, (operations[op_id].due_date if operations[op_id].due_date is not None else float('inf'), \n",
    "                               operations[op_id].processing_time, op_id))\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        # ==================================\n",
    "        #    POP OUT OPERATION USING EDD\n",
    "        # ==================================\n",
    "        i += 1\n",
    "        if not Q: \n",
    "            break\n",
    "        print_list = [item[2] for item in Q]\n",
    "        print_list.sort()\n",
    "        # print(f\"Iteration {i}: {print_list}\")\n",
    "        _, _, operation_id = heapq.heappop(Q)\n",
    "        operation = operations[operation_id]\n",
    "        # print(f\"{operation_id}\")\n",
    "        if operation.scheduled:\n",
    "            continue\n",
    "\n",
    "        # ==================================\n",
    "        #        COMPUTE START TIME\n",
    "        # ==================================\n",
    "        # Compute (tentative) start time based on dependencies\n",
    "        if operation.predecessors:\n",
    "            predecessor_max_end_time = max(\n",
    "                (operations[comp_id].end_time if operations[comp_id].end_time is not None else -float('inf'))\n",
    "                for comp_id in operation.predecessors)\n",
    "            minimum_start_time = predecessor_max_end_time\n",
    "            # if operation.id == \"J.6\":\n",
    "            #     print(operation.predecessors)\n",
    "            #     print(predecessor_max_end_time)\n",
    "        else:\n",
    "            minimum_start_time = 0\n",
    "\n",
    "        # Find the best machine and start time\n",
    "        workcenter = factory[str(operation.workcenter)]\n",
    "        machine_type = operation.machine\n",
    "        best_start_time = float('inf')\n",
    "        selected_machine = None\n",
    "\n",
    "        # ==================================\n",
    "        #           SELECT MACHINE\n",
    "        # ==================================\n",
    "        # Iterate through all functionally identical machine in the current workcenter\n",
    "        # Find the best start time, which is the earliest possible start time\n",
    "        list_machine_schedules = workcenter.machines[machine_type]\n",
    "        if operation.id == \"J.6\":\n",
    "            printer = True\n",
    "        else:\n",
    "            printer = False\n",
    "        for machine_idx, machine_usage in enumerate(list_machine_schedules): \n",
    "            start_time = EDD_find_earliest_start_time(machine_usage, minimum_start_time, operation.processing_time, print_button=printer)\n",
    "            if check_availability(start_time, operation.processing_time, machine_usage):\n",
    "                if start_time < best_start_time:\n",
    "                    # if operation.id == \"J.6\": \n",
    "                        # print(start_time)\n",
    "                    best_start_time = start_time\n",
    "                    selected_machine = machine_usage\n",
    "                    selected_machine_idx = machine_idx \n",
    "\n",
    "        if selected_machine is None:\n",
    "            # No available machine found; push operation back to recheck later\n",
    "            heapq.heappush(Q, (operation.due_date if operation.due_date is not None else float('inf'), operation.processing_time, operation_id))\n",
    "            # print(f\"Operation {operation.id} not scheduled yet, re-adding to the queue\")\n",
    "            continue\n",
    "\n",
    "        # ==================================\n",
    "        #      SCHEDULE THE OPERATIONS\n",
    "        # ==================================\n",
    "        operation.start_time = best_start_time\n",
    "        operation.end_time = operation.start_time + operation.processing_time\n",
    "        operation.scheduled = True\n",
    "        operation.scheduled_machine_idx = selected_machine_idx\n",
    "        scheduled_operations.append(operation)\n",
    "        # print(F\"Selected {operation.id}\")\n",
    "        # print(f\"Scheduled operations: {[op.id for op in scheduled_operations]}\")\n",
    "        # print(\"\")\n",
    "        workcenter.machines[machine_type][selected_machine_idx].append((operation.start_time, operation.end_time))\n",
    "\n",
    "        # ==================================\n",
    "        #           UPDATE QUEUE\n",
    "        # ==================================\n",
    "        # unscheduled_dependencies = {op_id: len(op.predecessors) for op_id, op in operations.items()}\n",
    "\n",
    "        for op_id, op in operations.items(): \n",
    "            for comp_id in op.predecessors: \n",
    "                # print(f\"my operation id: {operation.id}\")\n",
    "                # print(comp_id)\n",
    "                if operation.id == comp_id: \n",
    "                    # print(\"yes\")\n",
    "                    # if the id of the previously scheduled operation is the same as the id of the iterated Op\n",
    "                    # then we should reduce the unscheduled dependencies count by 1\n",
    "                    unscheduled_dependencies[op_id] -= 1\n",
    "                    # print(unscheduled_dependencies[op_id])\n",
    "        # print(f\"Unscheduled dependencies: {unscheduled_dependencies}\")\n",
    "\n",
    "        for op_id, count in unscheduled_dependencies.items():\n",
    "            scheduled_operations_id = [scheduled_op.id for scheduled_op in scheduled_operations]\n",
    "            list_Q = [queued_op[2] for queued_op in Q]\n",
    "            if (count == 0) and (op_id not in scheduled_operations_id) and (op_id not in list_Q):\n",
    "                heapq.heappush(Q, (operations[op_id].due_date if operations[op_id].due_date is not None else float('inf'), \n",
    "                                operations[op_id].processing_time, op_id))\n",
    "                # print(f\"Pushed {op_id} into Q\")\n",
    "\n",
    "\n",
    "\n",
    "        # for op_id, op in operations.items():\n",
    "        #     if not op.scheduled and op_id in unscheduled_dependencies:\n",
    "        #         # if the operation has not been scheduled, and is an unscheduled dependency\n",
    "        #         # for each of the predecessors of this operation\n",
    "        #         for comp_id in op.predecessors:\n",
    "        #             if operations[comp_id].scheduled:\n",
    "        #                 unscheduled_dependencies[op_id] -= 1\n",
    "        #         if unscheduled_dependencies[op_id] == 0:\n",
    "        #             heapq.heappush(Q, (op.due_date if op.due_date is not None else float('inf'), op.processing_time, op_id))\n",
    "        #             # print(f\"Operation {op_id} with no remaining dependencies added to the queue\")\n",
    "\n",
    "        # print(\"\")\n",
    "    return scheduled_operations\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_gantt_chart(factory, scheduled_operations):\n",
    "    y_labels = []\n",
    "    yticks = []\n",
    "    y_pos = 0\n",
    "    max_time = 0\n",
    "\n",
    "    for wc_id, wc in factory.items():\n",
    "        for machine_id, schedules in wc.machines.items():\n",
    "            for idx, tasks in enumerate(schedules):\n",
    "                y_label = f\"{wc_id} - {machine_id} - #{idx+1}\"\n",
    "                y_labels.append(y_label)\n",
    "                yticks.append(y_pos)\n",
    "\n",
    "                for task in tasks:\n",
    "                    start, end = task\n",
    "                    max_time = max(max_time, end)\n",
    "                    \n",
    "                y_pos += 1\n",
    "\n",
    "    fig_height = max(5, len(y_labels) * 0.6)\n",
    "    fig, ax = plt.subplots(figsize=(fig_height*2, fig_height))\n",
    "\n",
    "    for operation in scheduled_operations:\n",
    "        start, end = operation.start_time, operation.end_time\n",
    "        wc_id = operation.workcenter\n",
    "        machine_id = operation.machine\n",
    "        machine_idx = operation.scheduled_machine_idx\n",
    "\n",
    "        y_label = f\"{str(wc_id)} - {str(machine_id)} - #{int(machine_idx) + 1}\"\n",
    "        if y_label in y_labels:\n",
    "            y_pos = y_labels.index(y_label)\n",
    "            ax.add_patch(\n",
    "                mpatches.Rectangle(\n",
    "                    (start, y_pos - 0.4), end - start, 0.8,\n",
    "                    edgecolor='black', facecolor='skyblue'\n",
    "                )\n",
    "            )\n",
    "            ax.text(\n",
    "                (start + end) / 2, y_pos, f'{operation.id}\\n{start}-{end}',\n",
    "                ha='center', va='center', color='black'\n",
    "            )\n",
    "\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_yticklabels(y_labels)\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Workcenter - Machine - Index')\n",
    "    ax.set_xlim(0, max_time)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import networkx as nx\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Your BOM DataFrame\n",
    "# df_BOM = pd.DataFrame({\n",
    "#     'operation': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U'],\n",
    "#     'predecessor_operations': [[], [], [\"A\"], [\"B\"], [\"C\", \"D\"], [\"E\", \"G\"], [\"H\"], [], [\"F\"], [], [], [], [\"J\", \"K\", \"L\"], [\"M\"], [\"N\"], [], [], [\"P\", \"Q\"], [\"R\"], [\"S\", \"U\"], []],\n",
    "#     'end_product': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
    "#     'due_date': [None, None, None, None, None, None, None, None, 50.0, None, None, None, None, None, 80.0, None, None, None, None, 30.0, None],\n",
    "#     'processing_time': [3, 2, 1, 3, 1, 3, 5, 7, 4, 18, 12, 3, 5, 10, 4, 1, 8, 7, 5, 1, 8],\n",
    "#     'workcenter': ['WC#2', 'WC#1', 'WC#1', 'WC#2', 'WC#2', 'WC#2', 'WC#2', 'WC#3', 'WC#2', 'WC#1', 'WC#2', 'WC#3', 'WC#2', 'WC#2', 'WC#3', 'WC#2', 'WC#1', 'WC#1', 'WC#2', 'WC#3', 'WC#1'],\n",
    "#     'machine': [\"M1\", \"M2\", \"M3\", \"M2\", \"M4\", \"M5\", \"M1\", \"M2\", \"M3\", \"M4\", \"M5\", \"M1\", \"M2\", \"M3\", \"M2\", \"M3\", \"M4\", \"M5\", \"M1\", \"M4\", \"M2\"]\n",
    "# })\n",
    "\n",
    "# # Create a directed graph\n",
    "# G = nx.DiGraph()\n",
    "\n",
    "# # Add nodes and edges\n",
    "# for i, row in df_BOM.iterrows():\n",
    "#     G.add_node(row['operation'])\n",
    "#     for pred in row['predecessor_operations']:\n",
    "#         G.add_edge(pred, row['operation'])\n",
    "\n",
    "# # Generate positions for nodes\n",
    "# pos = nx.spring_layout(G)\n",
    "\n",
    "# # Adjust positions to create a hierarchical layout\n",
    "# levels = {}  # Dictionary to store levels of each node\n",
    "# for node in nx.topological_sort(G):\n",
    "#     if G.in_degree(node) == 0:\n",
    "#         levels[node] = 0\n",
    "#     else:\n",
    "#         levels[node] = max(levels[pred] for pred in G.predecessors(node)) + 1\n",
    "\n",
    "# # Adjust positions to reflect levels\n",
    "# for node, level in levels.items():\n",
    "#     pos[node][1] = -level\n",
    "\n",
    "# # Draw the graph\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# nx.draw(G, pos, with_labels=True, node_size=2000, node_color=\"lightblue\", font_size=10, font_weight=\"bold\", arrowsize=20)\n",
    "# plt.title(\"BOM Network Visualization with Hierarchical Layout\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_BOM = pd.DataFrame({\n",
    "#     'operation': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U'],\n",
    "#     'predecessor_operations': [[], [], [\"A\"], [\"B\"], [\"C\", \"D\"], [\"E\", \"G\"], [\"H\"], [], [\"F\"], [], [], [], [\"J\", \"K\", \"L\"], [\"M\"], [\"N\"], [], [], [\"P\", \"Q\"], [\"R\"], [\"S\", \"U\"], []],\n",
    "#     'end_product': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
    "#     'due_date': [None, None, None, None, None, None, None, None, 50.0, None, None, None, None, None, 80.0, None, None, None, None, 30.0, None],\n",
    "#     'processing_time': [3, 2, 1, 3, 1, 3, 5, 7, 4, 18, 12, 3, 5, 10, 4, 1, 8, 7, 5, 1, 8],\n",
    "#     'workcenter': ['WC#2', 'WC#1', 'WC#1', 'WC#2', 'WC#2', 'WC#2', 'WC#2', 'WC#3', 'WC#2', 'WC#1', 'WC#2', 'WC#3', 'WC#2', 'WC#2', 'WC#3', 'WC#2', 'WC#1', 'WC#1', 'WC#2', 'WC#3', 'WC#1'],\n",
    "#     'machine': [\"M1\", \"M2\", \"M3\", \"M2\", \"M4\", \"M5\", \"M1\", \"M2\", \"M3\", \"M4\", \"M5\", \"M1\", \"M2\", \"M3\", \"M2\", \"M3\", \"M4\", \"M5\", \"M1\", \"M4\", \"M2\"]\n",
    "# })\n",
    "# # display(df_BOM)\n",
    "# df_machine = pd.DataFrame({\n",
    "#     'workcenter': [\"WC#1\", \"WC#2\", \"WC#3\"],\n",
    "#     'M1': [3, 2, 3],\n",
    "#     'M2': [2, 1, 2],\n",
    "#     'M3': [1, 2, 1],\n",
    "#     'M4': [1, 1, 1],\n",
    "#     'M5': [1, 2, 3]\n",
    "# })\n",
    "# # display(df_machine)\n",
    "# factory = load_factory(df_machine)\n",
    "# operations = load_operations(df_BOM)\n",
    "# scheduled_operations = LETSA_schedule_operations(operations, factory)\n",
    "# # plot_gantt_chart(factory, scheduled_operations)\n",
    "# # print(calculate_makespan(factory))\n",
    "# df_schedule = format_schedule(scheduled_operations, factory)\n",
    "# display(df_schedule)\n",
    "\n",
    "# factory = load_factory(df_machine)\n",
    "# operations = load_operations(df_BOM)\n",
    "# scheduled_operations = EDD_schedule_operations(operations, factory)\n",
    "# # plot_gantt_chart(factory, scheduled_operations)\n",
    "# # print(calculate_makespan(factory))\n",
    "# df_schedule = format_schedule(scheduled_operations, factory)\n",
    "# display(df_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_machine = pd.DataFrame({\n",
    "#     'workcenter': [\"WC#1\", \"WC#2\", \"WC#3\"],\n",
    "#     'M1': [1, 1, 1],\n",
    "#     'M2': [2, 1, 1],\n",
    "# })\n",
    "\n",
    "# df_BOM = pd.read_csv(\"TestCases//30operations_2machines_0.15p_0.25D_(500,1000)dd.csv\")\n",
    "# df_BOM['predecessor_operations'] = df_BOM['predecessor_operations'].apply(lambda x: ast.literal_eval(x) if pd.notnull(x) else [])\n",
    "# # display(df_BOM)\n",
    "\n",
    "# # factory = load_factory(df_machine)\n",
    "# # operations = load_operations(df_BOM)\n",
    "# # scheduled_operations = LETSA_schedule_operations(operations, factory)\n",
    "# # plot_gantt_chart(factory, scheduled_operations)\n",
    "# # print(calculate_makespan(factory))\n",
    "# # df_schedule = format_schedule(scheduled_operations)\n",
    "# # display(df_schedule.sort_values(by='Operation'))\n",
    "\n",
    "# factory = load_factory(df_machine)\n",
    "# operations = load_operations(df_BOM)\n",
    "# scheduled_operations = EDD_schedule_operations(operations, factory)\n",
    "# # plot_gantt_chart(factory, scheduled_operations)\n",
    "# print(calculate_makespan(factory))\n",
    "# df_schedule = format_schedule(scheduled_operations)\n",
    "# display(df_schedule)\n",
    "# # display(df_schedule.sort_values(by='Operation'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_machine = pd.DataFrame({\n",
    "#     'workcenter': [\"WC#1\", \"WC#2\", \"WC#3\"],\n",
    "#     'M1': [1, 1, 1],\n",
    "#     'M2': [2, 1, 1],\n",
    "#     'M3': [1, 1, 1],\n",
    "#     'M4': [3, 1, 1],\n",
    "#     'M5': [1, 1, 1],\n",
    "# })\n",
    "\n",
    "# # filename = \"30operations_5machines_0.95p_0.75D_(500,750)dd.csv\"\n",
    "# # filename = \"100operations_1machines_0.15p_0.75D_(1000,4000)dd.csv\"\n",
    "# # df_BOM = pd.read_csv(f\"TestCases//{filename}\")\n",
    "# df_BOM['predecessor_operations'] = df_BOM['predecessor_operations'].apply(lambda x: ast.literal_eval(x) if pd.notnull(x) else [])\n",
    "# # display(df_BOM)\n",
    "\n",
    "# # factory = load_factory(df_machine)\n",
    "# # operations = load_operations(df_BOM)\n",
    "# # scheduled_operations = LETSA_schedule_operations(operations, factory)\n",
    "# # plot_gantt_chart(factory, scheduled_operations)\n",
    "# # print(calculate_makespan(factory))\n",
    "# # df_schedule = format_schedule(scheduled_operations)\n",
    "# # display(df_schedule.sort_values(by='Operation'))\n",
    "\n",
    "# print(\"\")\n",
    "# print(\"LETSA\")\n",
    "# factory = load_factory(df_machine)\n",
    "# operations = load_operations(df_BOM)\n",
    "# scheduled_operations = LETSA_schedule_operations(operations, factory)\n",
    "# # plot_gantt_chart(factory, scheduled_operations)\n",
    "# print(calculate_makespan(factory))\n",
    "# df_schedule = format_schedule(scheduled_operations)\n",
    "# display(df_schedule)\n",
    "# # df_schedule.to_csv(\"debug2.csv\")\n",
    "\n",
    "# factory = load_factory(df_machine)\n",
    "# operations = load_operations(df_BOM)\n",
    "# scheduled_operations = EDD_schedule_operations(operations, factory)\n",
    "# # plot_gantt_chart(factory, scheduled_operations)\n",
    "# # print(calculate_makespan(factory))\n",
    "# df_schedule = format_schedule(scheduled_operations)\n",
    "# display(df_schedule)\n",
    "# # display(df_schedule.sort_values(by='Operation'))\n",
    "# # df_schedule.to_csv(\"debug1.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============\n",
    "#       SA\n",
    "# ==============\n",
    "initial_temperature = 1000\n",
    "cooling_rate = 0.8\n",
    "min_temperature = 1\n",
    "iterations_per_temp = 10\n",
    "\n",
    "def SA_main(df_BOM, df_machine):\n",
    "    # Create an initial schedule\n",
    "    initial_schedule = SA_initial_solution(df_BOM)\n",
    "    # print(\"Initial Schedule:\", initial_schedule)\n",
    "\n",
    "    # Test the revised evaluation function with machine availability\n",
    "    initial_makespan, initial_usage = SA_calculate_makespan(initial_schedule, df_BOM, df_machine)\n",
    "    # print(\"Initial Makespan with Machine Availability:\", initial_makespan)\n",
    "\n",
    "    # Run the simulated annealing algorithm\n",
    "    best_schedule, best_makespan = simulated_annealing(df_BOM, df_machine, initial_schedule, initial_temperature, cooling_rate, min_temperature, iterations_per_temp)\n",
    "    # print(\"Best Schedule:\", best_schedule)\n",
    "    # print(\"Best Makespan:\", best_makespan)\n",
    "\n",
    "    # Generate the Gantt chart for the best schedule\n",
    "    # SA_generate_detailed_gantt_chart(best_schedule, df_BOM, best_makespan, df_machine)\n",
    "    # SA_generate_beautified_gantt_chart(best_schedule, df_BOM, df_machine)\n",
    "\n",
    "    # Export the best schedule to CSV\n",
    "    df = SA_format_schedule(best_schedule, df_BOM, df_machine)\n",
    "    return df, best_makespan\n",
    "\n",
    "def SA_initial_solution(df_BOM):\n",
    "    schedule = []\n",
    "    remaining_operations = set(df_BOM['operation'].tolist())\n",
    "    \n",
    "    while remaining_operations:\n",
    "        for op in list(remaining_operations):\n",
    "            predecessors = df_BOM[df_BOM['operation'] == op]['predecessor_operations'].values[0]\n",
    "            if all(pred in schedule for pred in predecessors):\n",
    "                schedule.append(op)\n",
    "                remaining_operations.remove(op)\n",
    "    \n",
    "    return schedule\n",
    "\n",
    "def SA_calculate_makespan(schedule, df_BOM, df_machine):\n",
    "    end_times = {}\n",
    "    machine_availability = {\n",
    "        workcenter: {machine: [0] * df_machine.loc[df_machine['workcenter'] == workcenter, machine].values[0]\n",
    "                     for machine in df_machine.columns if machine != 'workcenter'}\n",
    "        for workcenter in df_machine['workcenter']\n",
    "    }\n",
    "    workcenter_machine_usage = {\n",
    "        workcenter: {machine: [] for machine in df_machine.columns if machine != 'workcenter'}\n",
    "        for workcenter in df_machine['workcenter']\n",
    "    }\n",
    "\n",
    "    for op in schedule:\n",
    "        machine = df_BOM[df_BOM['operation'] == op]['machine'].values[0]\n",
    "        workcenter = df_BOM[df_BOM['operation'] == op]['workcenter'].values[0]\n",
    "        processing_time = df_BOM[df_BOM['operation'] == op]['processing_time'].values[0]\n",
    "        predecessors = df_BOM[df_BOM['operation'] == op]['predecessor_operations'].values[0]\n",
    "\n",
    "        # Calculate the earliest start time considering both predecessors and machine availability\n",
    "        start_time = max([end_times.get(pred, 0) for pred in predecessors], default=0)\n",
    "        \n",
    "        # Find the earliest available machine in the workcenter\n",
    "        earliest_machine_idx = min(range(len(machine_availability[workcenter][machine])), key=lambda x: machine_availability[workcenter][machine][x])\n",
    "        start_time = max(start_time, machine_availability[workcenter][machine][earliest_machine_idx])\n",
    "\n",
    "        # Calculate the end time of the operation\n",
    "        end_time = start_time + processing_time\n",
    "        end_times[op] = end_time\n",
    "\n",
    "        # Update the machine availability and usage\n",
    "        machine_availability[workcenter][machine][earliest_machine_idx] = end_time\n",
    "        workcenter_machine_usage[workcenter][machine].append((start_time, end_time, op, earliest_machine_idx))\n",
    "\n",
    "    return max(end_times.values()), workcenter_machine_usage\n",
    "\n",
    "\n",
    "def check_precedence_constraints(schedule, df_BOM):\n",
    "    # Function to check if the schedule respects precedence constraints\n",
    "    operation_positions = {op: idx for idx, op in enumerate(schedule)}\n",
    "    for _, row in df_BOM.iterrows():\n",
    "        operation = row['operation']\n",
    "        predecessors = row['predecessor_operations']\n",
    "        for pred in predecessors:\n",
    "            if operation_positions[pred] >= operation_positions[operation]:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def generate_neighbor(schedule, df_BOM, max_retries=100):\n",
    "    # Generate a neighbor solution by swapping two operations\n",
    "    new_schedule = schedule[:]\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        idx1, idx2 = random.sample(range(len(schedule)), 2)\n",
    "        new_schedule[idx1], new_schedule[idx2] = new_schedule[idx2], new_schedule[idx1]\n",
    "        if check_precedence_constraints(new_schedule, df_BOM):\n",
    "            return new_schedule\n",
    "        else:\n",
    "            new_schedule = schedule[:]\n",
    "        retries += 1\n",
    "    \n",
    "    # If no valid neighbor found, return the original schedule\n",
    "    print(\"Warning: Could not find a valid neighbor within retry limit.\")\n",
    "    return schedule\n",
    "\n",
    "\n",
    "def SA_accept_solution(current_makespan, new_makespan, temperature):\n",
    "    if new_makespan < current_makespan:\n",
    "        return True\n",
    "    else:\n",
    "        prob = np.exp((current_makespan - new_makespan) / temperature)\n",
    "        return random.random() < prob\n",
    "\n",
    "def simulated_annealing(df_BOM, df_machine, initial_schedule, initial_temperature, cooling_rate, min_temperature, iterations_per_temp):\n",
    "    current_schedule = initial_schedule\n",
    "    current_makespan, _ = SA_calculate_makespan(current_schedule, df_BOM, df_machine)\n",
    "    best_schedule = current_schedule\n",
    "    best_makespan = current_makespan\n",
    "    temperature = initial_temperature\n",
    "    # print(temperature)\n",
    "    while temperature > min_temperature:\n",
    "        for _ in range(iterations_per_temp):\n",
    "            new_schedule = SA_generate_neighbor(current_schedule, df_BOM)\n",
    "            new_makespan, _ = SA_calculate_makespan(new_schedule, df_BOM, df_machine)\n",
    "            \n",
    "            if SA_check_precedence_constraints(new_schedule, df_BOM) and SA_accept_solution(current_makespan, new_makespan, temperature):\n",
    "                current_schedule = new_schedule\n",
    "                current_makespan = new_makespan\n",
    "                \n",
    "                if new_makespan < best_makespan:\n",
    "                    best_schedule = new_schedule\n",
    "                    best_makespan = new_makespan\n",
    "        # print(temperature)\n",
    "        temperature *= cooling_rate\n",
    "    return best_schedule, best_makespan\n",
    "\n",
    "def SA_generate_detailed_gantt_chart(schedule, df_BOM, total_makespan, df_machine):\n",
    "    _, workcenter_machine_usage = SA_calculate_makespan(schedule, df_BOM, df_machine)\n",
    "\n",
    "    # Generate colors for each machine-workcenter combination\n",
    "    unique_machines = df_BOM['machine'].unique()\n",
    "    unique_workcenters = df_BOM['workcenter'].unique()\n",
    "    color_palette = plt.cm.get_cmap('tab20', len(unique_machines) * len(unique_workcenters))\n",
    "    color_index = 0\n",
    "    colors = {}\n",
    "    for wc in unique_workcenters:\n",
    "        for machine in unique_machines:\n",
    "            colors[(wc, machine)] = color_palette(color_index)\n",
    "            color_index += 1\n",
    "\n",
    "    # Plot the Gantt chart\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "    y_ticks = []\n",
    "    y_labels = []\n",
    "    y_position = 0\n",
    "\n",
    "    for wc in df_machine['workcenter']:\n",
    "        for machine in df_machine.columns:\n",
    "            if machine != 'workcenter':\n",
    "                num_machines = df_machine.loc[df_machine['workcenter'] == wc, machine].values[0]\n",
    "                for machine_idx in range(num_machines):\n",
    "                    if (wc in workcenter_machine_usage) and (machine in workcenter_machine_usage[wc]):\n",
    "                        for (start, end, op, used_machine_idx) in workcenter_machine_usage[wc][machine]:\n",
    "                            if used_machine_idx == machine_idx:\n",
    "                                ax.broken_barh([(start, end - start)], (y_position - 0.4, 0.8), facecolors=(colors[(wc, machine)]))\n",
    "                                ax.text(start, y_position, f\" {op} ({machine}-{machine_idx + 1})\", va='center', ha='left')\n",
    "\n",
    "                    y_ticks.append(y_position)\n",
    "                    y_labels.append(f\"{wc} {machine}-{machine_idx + 1}\")\n",
    "                    y_position += 1\n",
    "\n",
    "    ax.set_yticks(y_ticks)\n",
    "    ax.set_yticklabels(y_labels)\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Machine - Workcenter')\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Ensure the x-axis matches the total makespan\n",
    "    ax.set_xlim(0, total_makespan)\n",
    "\n",
    "    # Create a legend for the color-coded machine and workcenter\n",
    "    legend_patches = [mpatches.Patch(color=colors[(wc, machine)], label=f'{wc} - {machine}')\n",
    "                      for wc in unique_workcenters for machine in unique_machines]\n",
    "    ax.legend(handles=legend_patches, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def SA_generate_beautified_gantt_chart(schedule, df_BOM, df_machine):\n",
    "    schedule_data = []\n",
    "    operation_end_times = {}\n",
    "    machine_availability = {\n",
    "        workcenter: {machine: [0] * df_machine.loc[df_machine['workcenter'] == workcenter, machine].values[0]\n",
    "                     for machine in df_machine.columns if machine != 'workcenter'}\n",
    "        for workcenter in df_machine['workcenter']\n",
    "    }\n",
    "\n",
    "    # Define a light color palette for each workcenter\n",
    "    unique_workcenters = df_BOM['workcenter'].unique()\n",
    "    color_palette = plt.cm.get_cmap('Pastel1', len(unique_workcenters))\n",
    "    workcenter_colors = {workcenter: color_palette(i) for i, workcenter in enumerate(unique_workcenters)}\n",
    "\n",
    "    for op in schedule:\n",
    "        machine = df_BOM[df_BOM['operation'] == op]['machine'].values[0]\n",
    "        workcenter = df_BOM[df_BOM['operation'] == op]['workcenter'].values[0]\n",
    "        processing_time = df_BOM[df_BOM['operation'] == op]['processing_time'].values[0]\n",
    "        predecessors = df_BOM[df_BOM['operation'] == op]['predecessor_operations'].values[0]\n",
    "\n",
    "        # Calculate the earliest start time considering predecessors\n",
    "        start_time = max([operation_end_times.get(pred, 0) for pred in predecessors], default=0)\n",
    "        \n",
    "        # Find the earliest available machine in the workcenter\n",
    "        earliest_machine_idx = min(range(len(machine_availability[workcenter][machine])), key=lambda x: machine_availability[workcenter][machine][x])\n",
    "        start_time = max(start_time, machine_availability[workcenter][machine][earliest_machine_idx])\n",
    "\n",
    "        # Calculate the end time of the operation\n",
    "        end_time = start_time + processing_time\n",
    "        schedule_data.append({\n",
    "            'Operation': op,\n",
    "            'Start': start_time,\n",
    "            'End': end_time,\n",
    "            'Machine': machine,\n",
    "            'Workcenter': workcenter,\n",
    "            'Color': workcenter_colors[workcenter],\n",
    "            'MachineIdx': earliest_machine_idx + 1\n",
    "        })\n",
    "\n",
    "        # Update the availability time for the machine in the workcenter\n",
    "        machine_availability[workcenter][machine][earliest_machine_idx] = end_time\n",
    "        operation_end_times[op] = end_time\n",
    "\n",
    "    # Convert schedule data to DataFrame for plotting\n",
    "    df_schedule = pd.DataFrame(schedule_data)\n",
    "\n",
    "    # Plot the Gantt chart\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "    for idx, row in df_schedule.iterrows():\n",
    "        ax.broken_barh(\n",
    "            [(row['Start'], row['End'] - row['Start'])],\n",
    "            (idx - 0.4, 0.8),\n",
    "            facecolors=(row['Color'])\n",
    "        )\n",
    "        ax.text(\n",
    "            row['Start'] + 0.1,\n",
    "            idx,\n",
    "            f\"{row['Operation']} ({row['Machine']}-{row['MachineIdx']})\",\n",
    "            va='center',\n",
    "            ha='left',\n",
    "            color='black'\n",
    "        )\n",
    "\n",
    "    ax.set_yticks(range(len(df_schedule)))\n",
    "    ax.set_yticklabels(df_schedule['Operation'])\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Operations')\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Ensure the x-axis matches the total makespan\n",
    "    ax.set_xlim(0, df_schedule['End'].max())\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def SA_format_schedule(schedule, df_BOM, df_machine):\n",
    "    max_makespan, workcenter_machine_usage = SA_calculate_makespan(schedule, df_BOM, df_machine)\n",
    "    export_data = []\n",
    "\n",
    "    # Gather utilized machines information\n",
    "    used_machines = set()\n",
    "    for wc in workcenter_machine_usage:\n",
    "        for machine in workcenter_machine_usage[wc]:\n",
    "            for (start, end, op, machine_idx) in workcenter_machine_usage[wc][machine]:\n",
    "                used_machines.add((wc, machine, machine_idx))\n",
    "                export_data.append({\n",
    "                    'Operation': op,\n",
    "                    'Start': start,\n",
    "                    'End': end,\n",
    "                    'Workcenter': wc,\n",
    "                    'Machine': machine,\n",
    "                    'MachineIdx': machine_idx + 1\n",
    "                })\n",
    "\n",
    "\n",
    "\n",
    "    # Add unused machines information\n",
    "    for wc in df_machine['workcenter']:\n",
    "        for machine in df_machine.columns:\n",
    "            if machine != 'workcenter':\n",
    "                num_machines = df_machine.loc[df_machine['workcenter'] == wc, machine].values[0]\n",
    "                for idx in range(num_machines):\n",
    "                    if (wc, machine, idx) not in used_machines:\n",
    "                        export_data.append({\n",
    "                            'Operation': None,\n",
    "                            'Start': None,\n",
    "                            'End': None,\n",
    "                            'Workcenter': wc,\n",
    "                            'Machine': machine,\n",
    "                            'MachineIdx': idx + 1\n",
    "                        })\n",
    "    \n",
    "    return pd.DataFrame(export_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_BOM = pd.DataFrame({\n",
    "#     'operation': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U'],\n",
    "#     'predecessor_operations': [[], [], [\"A\"], [\"B\"], [\"C\", \"D\"], [\"E\", \"G\"], [\"H\"], [], [\"F\"], [], [], [], [\"J\", \"K\", \"L\"], [\"M\"], [\"N\"], [], [], [\"P\", \"Q\"], [\"R\"], [\"S\", \"U\"], []],\n",
    "#     'end_product': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
    "#     'due_date': [None, None, None, None, None, None, None, None, 50.0, None, None, None, None, None, 80.0, None, None, None, None, 30.0, None],\n",
    "#     'processing_time': [3, 2, 1, 3, 1, 3, 5, 7, 4, 18, 12, 3, 5, 10, 4, 1, 8, 7, 5, 1, 8],\n",
    "#     'workcenter': ['WC#2', 'WC#1', 'WC#1', 'WC#2', 'WC#2', 'WC#2', 'WC#2', 'WC#3', 'WC#2', 'WC#1', 'WC#2', 'WC#3', 'WC#2', 'WC#2', 'WC#3', 'WC#2', 'WC#1', 'WC#1', 'WC#2', 'WC#3', 'WC#1'],\n",
    "#     'machine': [\"M1\", \"M2\", \"M3\", \"M2\", \"M4\", \"M5\", \"M1\", \"M2\", \"M3\", \"M4\", \"M5\", \"M1\", \"M2\", \"M3\", \"M2\", \"M3\", \"M4\", \"M5\", \"M1\", \"M4\", \"M2\"]\n",
    "# })\n",
    "# display(df_BOM)\n",
    "# df_machine = pd.DataFrame({\n",
    "#     'workcenter': [\"WC#1\", \"WC#2\", \"WC#3\"],\n",
    "#     'M1': [3, 2, 3],\n",
    "#     'M2': [2, 1, 2],\n",
    "#     'M3': [1, 2, 1],\n",
    "#     'M4': [1, 1, 1],\n",
    "#     'M5': [1, 2, 3]\n",
    "# })\n",
    "\n",
    "# df, makespan = SA_main(df_BOM, df_machine)\n",
    "# display(df)\n",
    "# print(makespan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Systematic Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "def print_progress_bar(iteration, total, length=50):\n",
    "    if iteration == 0:\n",
    "        return  # Don't print the progress bar when no progress has been made.\n",
    "    percent = (\"{0:.1f}\").format(100 * (iteration / float(total)))\n",
    "    filled_length = int(length * iteration // total)\n",
    "    bar = '█' * filled_length + '-' * (length - filled_length)\n",
    "    sys.stdout.write(f'\\r|{bar}| {percent}% Complete')\n",
    "    sys.stdout.flush()\n",
    "    if iteration == total:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATING THE FACTORY INFORMATION\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "random.seed(42)\n",
    "n_workcenters, n_machines = 3, 5\n",
    "dict_machine = {}\n",
    "dict_machine[0] = pd.DataFrame({ 'workcenter': [f\"WC#{i}\" for i in range(1,n_workcenters+1)] })\n",
    "dict_machine[1] = pd.DataFrame({ 'workcenter': [f\"WC#{i}\" for i in range(1,n_workcenters+1)] })\n",
    "dict_machine[2] = pd.DataFrame({ 'workcenter': [f\"WC#{i}\" for i in range(1,n_workcenters+1)] })\n",
    "\n",
    "for machine_no in range(1,n_machines+1):\n",
    "    dict_machine[0][f\"M{machine_no}\"] = [random.randint(1,5) for _ in range(1,n_workcenters+1)]\n",
    "    dict_machine[1][f\"M{machine_no}\"] = [random.randint(1,3) for _ in range(1,n_workcenters+1)]\n",
    "    dict_machine[2][f\"M{machine_no}\"] = [random.randint(1,1) for _ in range(1,n_workcenters+1)]\n",
    "\n",
    "df_results = pd.DataFrame({\n",
    "    'filename': [None],\n",
    "    'LETSA_time_0': [None], 'EDD_time_0': [None], 'SA_time_0': [None],\n",
    "    'LETSA_time_1': [None], 'EDD_time_1': [None], 'SA_time_1': [None],\n",
    "    'LETSA_time_2': [None], 'EDD_time_2': [None], 'SA_time_2': [None],\n",
    "    'LETSA_makespan_0': [None], 'EDD_makespan_0': [None], 'SA_makespan_0': [None],    \n",
    "    'LETSA_makespan_1': [None], 'EDD_makespan_1': [None], 'SA_makespan_1': [None],\n",
    "    'LETSA_makespan_2': [None], 'EDD_makespan_2': [None], 'SA_makespan_2': [None]    \n",
    "})\n",
    "\n",
    "paths = os.listdir('TestCases') \n",
    "folders =  [item for item in paths if item[-3:] != \"csv\"]\n",
    "folders.sort(reverse=True)\n",
    "for folder in folders: \n",
    "    print(f\"Running code for {folder}\")\n",
    "    files = os.listdir(f\"TestCases//{folder}\")\n",
    "    if not os.path.exists(f\"TestResults//{folder}\"):\n",
    "        os.makedirs(f\"TestResults//{folder}\")\n",
    "\n",
    "    # # ===============\n",
    "    # #      LETSA\n",
    "    # # ===============\n",
    "    # print(\"Testing cases for LETSA\")\n",
    "    # for i, filename in enumerate(files): \n",
    "    #     df_BOM = pd.read_csv(f\"TestCases//{folder}//{filename}\")\n",
    "    #     df_BOM['predecessor_operations'] = df_BOM['predecessor_operations'].apply(lambda x: ast.literal_eval(x) if pd.notnull(x) else [])\n",
    "    #     df_results.at[i, \"filename\"] = filename\n",
    "\n",
    "    #     for j in range(3): \n",
    "    #         df_machine = dict_machine[j]\n",
    "    #         start = time.time()\n",
    "    #         factory = load_factory(df_machine)\n",
    "    #         operations = load_operations(df_BOM)\n",
    "    #         LETSA_scheduled_operations = LETSA_schedule_operations(operations, factory)\n",
    "    #         end = time.time()\n",
    "\n",
    "    #         df_results.at[i, f\"LETSA_time_{j}\"] = start - end\n",
    "    #         df_results.at[i, f\"LETSA_makespan_{j}\"] = calculate_makespan(factory)\n",
    "    #         df_scheduled = format_schedule(LETSA_scheduled_operations, factory)\n",
    "    #         df_scheduled.to_csv(f\"TestResults//{folder}//{filename[:-4]}_LETSA_{j}.csv\")\n",
    "    #         print_progress_bar((i*3)+(j+1), (3*len(files)))\n",
    "\n",
    "    #     if i % 10 == 0: \n",
    "    #         df_results.to_csv(\"TestResults//TestResults.csv\")\n",
    "\n",
    "    # # ===============\n",
    "    # #       EDD\n",
    "    # # ===============\n",
    "    # print(\"Testing cases for EDD\")\n",
    "    # for i, filename in enumerate(files): \n",
    "    #     df_BOM = pd.read_csv(f\"TestCases//{folder}//{filename}\")\n",
    "    #     df_BOM['predecessor_operations'] = df_BOM['predecessor_operations'].apply(lambda x: ast.literal_eval(x) if pd.notnull(x) else [])\n",
    "    #     df_results.at[i, \"filename\"] = filename\n",
    "\n",
    "    #     for j in range(3): \n",
    "    #         df_machine = dict_machine[j]\n",
    "    #         start = time.time()\n",
    "    #         factory = load_factory(df_machine)\n",
    "    #         operations = load_operations(df_BOM)\n",
    "    #         EDD_scheduled_operations = EDD_schedule_operations(operations, factory)\n",
    "    #         end = time.time()\n",
    "\n",
    "    #         df_results.at[i, f\"EDD_time_{j}\"] = end - start\n",
    "    #         df_results.at[i, f\"EDD_makespan_{j}\"] = calculate_makespan(factory)\n",
    "    #         df_scheduled = format_schedule(EDD_scheduled_operations, factory)\n",
    "    #         df_scheduled.to_csv(f\"TestResults//{folder}//{filename[:-4]}_EDD_{j}.csv\")\n",
    "    #         print_progress_bar((i*3)+(j+1), (3*len(files)))\n",
    "\n",
    "    #     if i % 10 == 0: \n",
    "    #         df_results.to_csv(\"TestResults//TestResults.csv\")\n",
    "\n",
    "    # ===============\n",
    "    #       SA\n",
    "    # ===============\n",
    "    print(\"Testing cases for SA\")\n",
    "    for i, filename in enumerate(files): \n",
    "        df_BOM = pd.read_csv(f\"TestCases//{folder}//{filename}\")\n",
    "        df_BOM['predecessor_operations'] = df_BOM['predecessor_operations'].apply(lambda x: ast.literal_eval(x) if pd.notnull(x) else [])\n",
    "        df_results.at[i, \"filename\"] = filename\n",
    "\n",
    "        for j in range(3): \n",
    "            df_machine = dict_machine[j]\n",
    "\n",
    "            start = time.time()\n",
    "            df_scheduled, best_makespan = SA_main(df_BOM, df_machine)\n",
    "            end = time.time()\n",
    "\n",
    "            df_results.at[i, f\"SA_makespan_{j}\"] = best_makespan\n",
    "            df_results.at[i, f\"SA_time_{j}\"] = end - start \n",
    "            df_scheduled.to_csv(f\"TestResults//{folder}//{filename[:-4]}_SA_{j}.csv\")\n",
    "            print_progress_bar((i*3)+(j+1), (3*len(files)))\n",
    "\n",
    "        if i % 10 == 0: \n",
    "            df_results.to_csv(\"TestResults//TestResults.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BOM = pd.read_csv(f\"TestCases//{folder}//{filename}\")\n",
    "df_BOM['predecessor_operations'] = df_BOM['predecessor_operations'].apply(lambda x: ast.literal_eval(x) if pd.notnull(x) else [])\n",
    "df_results.at[i, \"filename\"] = filename\n",
    "\n",
    "for j in range(3): \n",
    "    df_machine = dict_machine[j]\n",
    "\n",
    "    start = time.time()\n",
    "    df_scheduled, best_makespan = SA_main(df_BOM, df_machine)\n",
    "    end = time.time()\n",
    "\n",
    "    df_results.at[i, f\"SA_makespan_{j}\"] = best_makespan\n",
    "    df_results.at[i, f\"SA_time_{j}\"] = end - start \n",
    "    df_scheduled.to_csv(f\"TestResults//{folder}//{filename[:-4]}_SA_{j}.csv\")\n",
    "    print_progress_bar((i*3)+(j+1), (3*len(files)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asdfasdfasdfasdfasdf\n"
     ]
    }
   ],
   "source": [
    "x = \"asdfasdfasdfasdfasdf.csv\"\n",
    "print(x[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "30\n",
      "60\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    if i % 30 == 0:\n",
    "        print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
