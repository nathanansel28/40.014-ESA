{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# LETSA\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "import os\n",
    "import time\n",
    "import ast\n",
    "from functools import cache\n",
    "\n",
    "# SA\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# EDD\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LETSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LETSAWorkCenter:\n",
    "    def __init__(self, id, dict_machines={}):\n",
    "        self.id = str(id)\n",
    "        self.machines = dict_machines\n",
    "        # dict_machines = {'M1': [ [], [], [] ] }\n",
    "\n",
    "class LETSAOperation:\n",
    "    def __init__(self, id, processing_time, workcenter, machine, due_date=None, successors=None, predecessors=None):\n",
    "        self.id = str(id)\n",
    "        self.successor = str(successors) if successors else None\n",
    "        self.predecessors = predecessors if predecessors else []\n",
    "        self.workcenter = str(workcenter)\n",
    "        self.machine = str(machine)\n",
    "        self.processing_time = processing_time\n",
    "        self.start_time = None\n",
    "        self.end_time = None\n",
    "        self.due_date = None if due_date != due_date else due_date\n",
    "        self.scheduled = False\n",
    "\n",
    "def LETSA_load_operations(df):\n",
    "    \"\"\"\n",
    "    Loads the operation information from the df_BOM\n",
    "    Initializes an Operation object for each of the operation and stores it in the operations dictionary\n",
    "    Inputs: \n",
    "        - df            : a dataframe consisting the BOM information  \n",
    "        - filename      : \n",
    "    Outputs:\n",
    "        - operations    : \n",
    "    \"\"\"\n",
    "\n",
    "    operations = {}\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        op = LETSAOperation(\n",
    "            id=str(row['operation']),\n",
    "            processing_time=row['processing_time'],\n",
    "            workcenter=row['workcenter'],\n",
    "            machine=row['machine'],\n",
    "            due_date=row['due_date'],\n",
    "            predecessors=row['predecessor_operations']\n",
    "        )\n",
    "        operations[op.id] = op\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        current_op_id = row['operation']\n",
    "        predecessor_ops = row['predecessor_operations']\n",
    "        for predecessor in predecessor_ops:\n",
    "            operations[predecessor].successor = current_op_id\n",
    "    \n",
    "    return operations\n",
    "\n",
    "def LETSA_load_factory(df_machine):\n",
    "    factory = {}\n",
    "    for idx, row in df_machine.iterrows():\n",
    "        workcenter = row['workcenter']\n",
    "        dict_machines = {}\n",
    "        for machine in (df_machine.columns[1:]): \n",
    "            dict_machines[machine] = [[] for _ in range(row[machine])]\n",
    "        # factory.append(WorkCenter(workcenter, dict_machines=dict_machines))\n",
    "        factory[workcenter] = LETSAWorkCenter(workcenter, dict_machines=dict_machines)\n",
    "    return factory \n",
    "\n",
    "def LETSA_find_critical_path(operations, feasible_operations): \n",
    "    \"\"\"\n",
    "    Finds the critical path among the feasible operations.\n",
    "    Inputs:\n",
    "        - operations                    : dictionary {operation_id: Operation()}, a dictionary of all operations\n",
    "        - feasible_operations           : list[operation_id],  a list of operation IDs that are currently feasible\n",
    "    Output:\n",
    "        - critical_path, critical_length\n",
    "    \"\"\"\n",
    "\n",
    "    def dfs(operations, current_op_id, path, path_length, all_paths):\n",
    "        \"\"\" \n",
    "        Performs recursive DFS on the operation network. \n",
    "        Inputs: \n",
    "            - operations                : dictionary {operation_id: Operation()}, dictionary of all operations \n",
    "            - current_op_id             : str, the ID of the node at which the DFS is performed\n",
    "            - path                      : list, to keep track of current path\n",
    "            - path_length               : float, to keep track of current path length\n",
    "            - all_paths                 : list, to keep track of all possible paths \n",
    "        Output: \n",
    "            - None, perform in place\n",
    "        \"\"\"\n",
    "\n",
    "        path.append(current_op_id)\n",
    "        path_length += operations[current_op_id].processing_time\n",
    "        \n",
    "        if not operations[current_op_id].predecessors:\n",
    "            all_paths.append((list(path), path_length))\n",
    "        else:\n",
    "            for pred in operations[current_op_id].predecessors:\n",
    "                dfs(operations, pred, path, path_length, all_paths)\n",
    "        \n",
    "        path.pop()\n",
    "        path_length -= operations[current_op_id].processing_time\n",
    "\n",
    "    def find_all_paths(operations, feasible_operations):\n",
    "        \"\"\"\n",
    "        Calls DFS on all the feasible operations. \n",
    "        Inputs: \n",
    "            - operations                : dictionary {operation_id: Operation()}, dictionary of all operations \n",
    "            - feasible_operations       : list [operation_id], list of all feasible operations to perform DFS on \n",
    "        \"\"\"\n",
    "\n",
    "        all_paths = []\n",
    "        for op_id in feasible_operations:\n",
    "            dfs(operations, op_id, [], 0, all_paths)\n",
    "        return all_paths\n",
    "\n",
    "    all_paths = find_all_paths(operations, feasible_operations)\n",
    "    # print(\"     printing all paths\")\n",
    "    # for path in all_paths: \n",
    "        # print(path[0], path[1])\n",
    "    critical_path, critical_length = max(all_paths, key=lambda x:x[1])\n",
    "\n",
    "    return critical_path, critical_length\n",
    "\n",
    "def LETSA_schedule_operations(operations, factory):\n",
    "    \"\"\"\n",
    "    Solves the assembly scheduling problem (ASP) using the Longest End Time Scheduling Algorithm (LETSA).\n",
    "    Inputs:\n",
    "        - operations            : dictionary {operation_id: Operation()}, a dictionary of all operations.\n",
    "        - factory               : list [WorkCenter()], a list of WorkCenter objects, containing machine information and availability\n",
    "    Output:\n",
    "        - scheduled_operations  : list [Operation()], a list of Operation objects with start and end time schedules.\n",
    "    \"\"\"\n",
    "\n",
    "    scheduled_operations = []\n",
    "    # [[Step 4]]\n",
    "    i = 1\n",
    "    while True:\n",
    "        # print(f\"Iteration {i}\")\n",
    "        # ================================================================================================================\n",
    "        #  [[4.0]] Feasible operations = every operation that is \n",
    "        #                               (1) not scheduled, and \n",
    "        #                               (2) has all successors scheduled, OR does not have any successors\n",
    "        # ================================================================================================================\n",
    "        feasible_operations = [op_id for op_id, op in operations.items() if ((not op.scheduled) and (op.successor==None or operations[op.successor].scheduled))]\n",
    "        # print(f\"feasible operations: {feasible_operations}\")\n",
    "        if not feasible_operations:\n",
    "            break # terminate if all operations have been scheduled\n",
    "\n",
    "        # ===================================================================\n",
    "        #  [[4.1 - 4.3]] Compute critical path only for feasible operations\n",
    "        # ===================================================================\n",
    "        critical_path, length = LETSA_find_critical_path(operations, feasible_operations)\n",
    "        selected_operation_id = critical_path[0]\n",
    "        selected_operation = operations[selected_operation_id]\n",
    "        # print(f\"critical path: {critical_path}, length: {length}\")\n",
    "        # print(f\"selected operation: {selected_operation_id}\")\n",
    "\n",
    "        # =====================================================================\n",
    "        # [[4.4]] Set completion/end time of the selected operation as\n",
    "        #         (ii) the start time of the successor, if a successor exists\n",
    "        #         (ii) the project deadline, otherwise \n",
    "        # =====================================================================\n",
    "        if selected_operation.successor: \n",
    "            # if the operation has a successor \n",
    "            # then the tentative end time is the start time of the successor\n",
    "            successor_id = selected_operation.successor\n",
    "            tentative_completion_time = operations[successor_id].start_time\n",
    "        else: \n",
    "            # else, the operation is an end product and its tentative completion time must be its own deadline\n",
    "            tentative_completion_time = selected_operation.due_date\n",
    "\n",
    "        # ============================================================================\n",
    "        #   [[4.5]] For each identical machine incuded in the required work-center \n",
    "        # ============================================================================\n",
    "        def check_availability(time, machine_usage): \n",
    "            \"\"\"\n",
    "            Returns True if the time interval does not overlap with any intervals in machine_usage, False otherwise.\n",
    "                time            : (start, end)\n",
    "                machine_usage   : list of tuples [(start1, end1), (start2, end2), ...]\n",
    "            \"\"\"\n",
    "            start, end = time\n",
    "            for interval in machine_usage:\n",
    "                interval_start, interval_end = interval\n",
    "                if not (end <= interval_start or start >= interval_end):\n",
    "                    return False\n",
    "            return True\n",
    "\n",
    "        def find_latest_start_time(completion_time, processing_time, machine_usage):\n",
    "            \"\"\"\n",
    "            completion_time : float\n",
    "            processing_time : float\n",
    "            machine_usage   : list of tuples [(start1, end1), (start2, end2), ...]\n",
    "            \n",
    "            Returns the latest possible start time such that the job can be completed\n",
    "            before the completion time and does not overlap with any intervals in machine_usage.\n",
    "            \"\"\"\n",
    "            latest_start_time = completion_time - processing_time\n",
    "\n",
    "            # Sort the machine usage intervals by their start times\n",
    "            machine_usage = sorted(machine_usage, key=lambda x: x[0])\n",
    "            \n",
    "            # Iterate over the machine usage intervals in reverse order\n",
    "            for interval in reversed(machine_usage):\n",
    "                interval_start, interval_end = interval\n",
    "                \n",
    "                # Check if there is a gap between the intervals where the job can fit\n",
    "                if interval_end <= latest_start_time:\n",
    "                    if check_availability((latest_start_time, latest_start_time + processing_time), machine_usage):\n",
    "                        return latest_start_time\n",
    "                latest_start_time = min(latest_start_time, interval_start - processing_time)\n",
    "            \n",
    "            # Check if the latest possible start time is valid\n",
    "            if check_availability((latest_start_time, latest_start_time + processing_time), machine_usage):\n",
    "                return latest_start_time\n",
    "            \n",
    "            return None\n",
    "\n",
    "        current_workcenter_id = str(selected_operation.workcenter)\n",
    "        # print(type(current_workcenter_id))\n",
    "        # print(factory)\n",
    "        current_workcenter = factory[current_workcenter_id]             # WorkCenter object \n",
    "        machine_type = str(selected_operation.machine)                  # machine id of required machine\n",
    "        possible_machines = current_workcenter.machines[machine_type]   # [[], [], []]\n",
    "\n",
    "        processing_time = selected_operation.processing_time\n",
    "        tentative_start_time = tentative_completion_time - processing_time\n",
    "        possible_start_times = []\n",
    "        for machine_idx, machine_schedule in enumerate(possible_machines):\n",
    "            # print(machine_idx, machine_schedule)\n",
    "            # if not machine_schedule:  # If machine schedule is empty, then machine is immediately useable\n",
    "            #     latest_available_start_time = tentative_completion_time - selected_operation.processing_time\n",
    "            if check_availability((tentative_start_time, tentative_completion_time), machine_schedule) :\n",
    "                start_time, end_time = tentative_start_time, tentative_completion_time\n",
    "            else: \n",
    "                start_time = find_latest_start_time(tentative_completion_time, processing_time, machine_schedule) \n",
    "                end_time = start_time + processing_time\n",
    "            possible_start_times.append((machine_idx, start_time, end_time))\n",
    "            # print(start_time, end_time)\n",
    "\n",
    "        # ============================================================================\n",
    "        #   [[4.6]] Select a machine to schedule operation Jc  \n",
    "        # ============================================================================\n",
    "        selected_machine, finalized_start_time, finalized_end_time = max(possible_start_times, key=lambda x:x[1]) \n",
    "        current_workcenter.machines[machine_type][machine_idx].append((finalized_start_time, finalized_end_time))\n",
    "\n",
    "        # ============================================================================\n",
    "        #   [[4.7]] Delete operation Jc from the network\n",
    "        #   [[4.8]] Add all eligible operations into the list of feasible operations     \n",
    "        # ============================================================================\n",
    "        selected_operation.start_time = start_time\n",
    "        selected_operation.end_time = end_time\n",
    "        selected_operation.scheduled = True\n",
    "        scheduled_operations.append(selected_operation)\n",
    "\n",
    "        i += 1 \n",
    "        # print()\n",
    "        \n",
    "    return scheduled_operations\n",
    "\n",
    "def LETSA_plot_gantt_chart(scheduled_operations, plot_path=None, plot_name=None):   \n",
    "    fig, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "    # Get unique work centers\n",
    "    workcenters = list(set(str(op.workcenter) for op in scheduled_operations))\n",
    "    # print(f\"Unique workcenters: {workcenters}\")\n",
    "    # print(workcenters)\n",
    "\n",
    "    # Generate colors for each work center\n",
    "    available_colors = plt.cm.tab20.colors\n",
    "    num_colors = len(available_colors)\n",
    "    colors = {workcenter: available_colors[i % num_colors] for i, workcenter in enumerate(workcenters)}\n",
    "    # print(f\"Colors dictionary: {colors}\")\n",
    "\n",
    "    for op in scheduled_operations:\n",
    "        workcenter = str(op.workcenter)\n",
    "        # print(f\"Processing operation {op.id} for workcenter {workcenter}\")\n",
    "        \n",
    "        start = op.start_time\n",
    "        end = op.end_time\n",
    "        \n",
    "        if workcenter not in colors:\n",
    "            print(f\"Workcenter {workcenter} not found in colors dictionary\")\n",
    "            continue\n",
    "        \n",
    "        ax.barh(workcenter, end - start, left=start, color=colors[workcenter], edgecolor='black')\n",
    "        ax.text(start + (end - start) / 2, workcenter, op.id, ha='center', va='center', color='black')\n",
    "\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Work Center')\n",
    "    ax.set_title('Gantt Chart of LETSA schedule')\n",
    "    ax.set_yticks(range(len(workcenters)))\n",
    "    ax.set_yticklabels(workcenters)\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "    if plot_path: \n",
    "        plt.savefig(f\"{plot_path}//{plot_name}.png\")\n",
    "        plt.close(fig)\n",
    "        plt.clf()\n",
    "\n",
    "def LETSA_calculate_makespan(factory):\n",
    "    list_schedules = []\n",
    "    for workcenter_key in factory:\n",
    "        for _, machine_schedule in factory[workcenter_key].machines.items():\n",
    "            flattened_schedule = [item for sublist in machine_schedule for item in sublist]\n",
    "            list_schedules += flattened_schedule\n",
    "\n",
    "    _max = max(list_schedules, key=lambda x: x[1])[1]\n",
    "    _min = min(list_schedules, key=lambda x: x[0])[0]\n",
    "\n",
    "    return _max - _min\n",
    "\n",
    "print(LETSA_calculate_makespan(factory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BOM = pd.DataFrame({\n",
    "    'operation': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U'],\n",
    "    'predecessor_operations': [[], [], [\"A\"], [\"B\"], [\"C\", \"D\"], [\"E\", \"G\"], [\"H\"], [], [\"F\"], [], [], [], [\"J\", \"K\", \"L\"], [\"M\"], [\"N\"], [], [], [\"P\", \"Q\"], [\"R\"], [\"S\", \"U\"], []],\n",
    "    'end_product': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
    "    'due_date': [None, None, None, None, None, None, None, None, 50.0, None, None, None, None, None, 80.0, None, None, None, None, 30.0, None],\n",
    "    'processing_time': [3, 2, 1, 3, 1, 3, 5, 7, 4, 18, 12, 3, 5, 10, 4, 1, 8, 7, 5, 1, 8],\n",
    "    'workcenter': ['WC#2', 'WC#1', 'WC#1', 'WC#2', 'WC#2', 'WC#2', 'WC#2', 'WC#3', 'WC#2', 'WC#1', 'WC#2', 'WC#3', 'WC#2', 'WC#2', 'WC#3', 'WC#2', 'WC#1', 'WC#1', 'WC#2', 'WC#3', 'WC#1'],\n",
    "    'machine': [\"M1\", \"M2\", \"M3\", \"M2\", \"M4\", \"M5\", \"M1\", \"M2\", \"M3\", \"M4\", \"M5\", \"M1\", \"M2\", \"M3\", \"M2\", \"M3\", \"M4\", \"M5\", \"M1\", \"M4\", \"M2\"]\n",
    "})\n",
    "df_machine = pd.DataFrame({\n",
    "    'workcenter': [\"WC#1\", \"WC#2\", \"WC#3\"],\n",
    "    'M1': [3, 2, 3],\n",
    "    'M2': [2, 1, 2],\n",
    "    'M3': [1, 2, 1],\n",
    "    'M4': [1, 1, 1],\n",
    "    'M5': [1, 2, 3]\n",
    "})\n",
    "factory = LETSA_load_factory(df_machine)\n",
    "operations = LETSA_load_operations(df_BOM)\n",
    "scheduled_operations = LETSA_schedule_operations(operations, factory)\n",
    "# LETSA_plot_gantt_chart(scheduled_operations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.0\n"
     ]
    }
   ],
   "source": [
    "def LETSA_calculate_makespan(factory):\n",
    "    list_schedules = []\n",
    "    for workcenter_key in factory:\n",
    "        for _, machine_schedule in factory[workcenter_key].machines.items():\n",
    "            flattened_schedule = [item for sublist in machine_schedule for item in sublist]\n",
    "            list_schedules += flattened_schedule\n",
    "\n",
    "    _max = max(list_schedules, key=lambda x: x[1])[1]\n",
    "    _min = min(list_schedules, key=lambda x: x[0])[0]\n",
    "\n",
    "    return _max - _min\n",
    "\n",
    "print(LETSA_calculate_makespan(factory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============\n",
    "#     EDD\n",
    "# ==============\n",
    "class EDDOperation:\n",
    "    def __init__(self, id, predecessor_operations, end_product, due_date, processing_time, workcenter, machine):\n",
    "        self.id = str(id)\n",
    "        self.predecessor_operations = predecessor_operations\n",
    "        self.end_product = end_product\n",
    "        self.due_date = due_date\n",
    "        self.processing_time = processing_time\n",
    "        self.workcenter = str(workcenter)\n",
    "        self.machine = str(machine)\n",
    "        self.start_time = None\n",
    "        self.end_time = None\n",
    "        self.scheduled = False\n",
    "\n",
    "class EDDWorkCenter:\n",
    "    def __init__(self, id, dict_machines={}):\n",
    "        self.id = str(id)\n",
    "        self.machines = dict_machines\n",
    "\n",
    "def EDD_load_operations(df):\n",
    "    operations = {}\n",
    "    for _, row in df.iterrows():\n",
    "        op_id = row['operation']\n",
    "        operations[op_id] = EDDOperation(\n",
    "            id=op_id,\n",
    "            processing_time=row['processing_time'],\n",
    "            workcenter=row['workcenter'],\n",
    "            machine=row['machine'],\n",
    "            predecessor_operations=row['predecessor_operations'] if isinstance(row['predecessor_operations'], list) else [],\n",
    "            end_product=row['end_product'],\n",
    "            due_date=row['due_date']\n",
    "        )\n",
    "    return operations\n",
    "\n",
    "def EDD_load_factory(df_machine):\n",
    "    factory = {}\n",
    "    for _, row in df_machine.iterrows():\n",
    "        workcenter_id = row['workcenter']\n",
    "        machines = {machine: [] for machine in df_machine.columns[1:] if row[machine] > 0}\n",
    "        factory[workcenter_id] = EDDWorkCenter(id=workcenter_id, dict_machines=machines)\n",
    "    return factory\n",
    "\n",
    "def EDD_find_earliest_start_time(machine_usage, desired_start_time, processing_time):\n",
    "    \"\"\"\n",
    "    Finds the earliest start time on the given machine that avoids overlapping with existing jobs.\n",
    "    \"\"\"\n",
    "    # Ensure machine_usage is a list of tuples\n",
    "    if not all(isinstance(interval, tuple) and len(interval) == 2 for interval in machine_usage):\n",
    "        raise ValueError(\"Machine usage must be a list of tuples with exactly two values each.\")\n",
    "    \n",
    "    # Flatten the list of usage intervals\n",
    "    flat_usage = [interval for interval in machine_usage]\n",
    "    flat_usage.sort()\n",
    "    \n",
    "    # print(f\"Machine usage: {flat_usage}\")\n",
    "    # print(f\"Desired start time: {desired_start_time}, Processing time: {processing_time}\")\n",
    "\n",
    "    if not flat_usage:\n",
    "        return desired_start_time\n",
    "\n",
    "    for i in range(len(flat_usage) + 1):\n",
    "        if i == 0:\n",
    "            interval_start = 0\n",
    "            interval_end = flat_usage[i][0] if len(flat_usage) > 0 else float('inf')\n",
    "        elif i == len(flat_usage):\n",
    "            interval_start = flat_usage[i - 1][1]\n",
    "            interval_end = float('inf')\n",
    "        else:\n",
    "            interval_start = flat_usage[i - 1][1]\n",
    "            interval_end = flat_usage[i][0]\n",
    "\n",
    "        # print(f\"Checking interval: ({interval_start}, {interval_end})\")\n",
    "\n",
    "        if desired_start_time >= interval_start and desired_start_time + processing_time <= interval_end:\n",
    "            return desired_start_time\n",
    "\n",
    "        if interval_start + processing_time <= interval_end:\n",
    "            return interval_start\n",
    "\n",
    "    return desired_start_time\n",
    "\n",
    "def EDD_schedule_operations(operations, factory):\n",
    "    def check_availability(start_time, processing_time, machine_usage):\n",
    "        \"\"\"\n",
    "        Returns True if the time interval does not overlap with any intervals in machine_usage, False otherwise.\n",
    "        \"\"\"\n",
    "        end_time = start_time + processing_time\n",
    "        for interval in machine_usage:\n",
    "            if len(interval) != 2:\n",
    "                raise ValueError(\"Machine usage interval does not contain exactly 2 values\")\n",
    "            interval_start, interval_end = interval\n",
    "            if not (end_time <= interval_start or start_time >= interval_end):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    scheduled_operations = []\n",
    "    Q = []\n",
    "    unscheduled_dependencies = {op_id: len(op.predecessor_operations) for op_id, op in operations.items()}\n",
    "\n",
    "    # Initialize the queue with operations that have no dependencies, sorted by due dates\n",
    "    for op_id, count in unscheduled_dependencies.items():\n",
    "        if count == 0:\n",
    "            heapq.heappush(Q, (operations[op_id].due_date if operations[op_id].due_date is not None else float('inf'), operations[op_id].processing_time, op_id))\n",
    "\n",
    "    while Q:\n",
    "        _, _, operation_id = heapq.heappop(Q)\n",
    "        operation = operations[operation_id]\n",
    "\n",
    "        if operation.scheduled:\n",
    "            continue\n",
    "\n",
    "        # Compute start time based on dependencies\n",
    "        if operation.predecessor_operations:\n",
    "            max_end_time = max(\n",
    "                (operations[comp_id].end_time if operations[comp_id].end_time is not None else -float('inf'))\n",
    "                for comp_id in operation.predecessor_operations\n",
    "            )\n",
    "            operation.start_time = max_end_time\n",
    "        else:\n",
    "            operation.start_time = 0\n",
    "\n",
    "        # Find the best machine and start time\n",
    "        workcenter = factory[str(operation.workcenter)]\n",
    "        best_start_time = float('inf')\n",
    "        selected_machine = None\n",
    "        selected_machine_name = None\n",
    "        \n",
    "        for machine_name, machine_usages in workcenter.machines.items():\n",
    "            # print(f\"Machine: {machine_name}, Usages: {machine_usages}\")\n",
    "            \n",
    "            # Ensure machine_usages is a list of tuples\n",
    "            if not all(isinstance(interval, tuple) and len(interval) == 2 for interval in machine_usages):\n",
    "                raise ValueError(f\"Machine usages for {machine_name} in workcenter {operation.workcenter} must be a list of tuples with exactly two values each.\")\n",
    "                \n",
    "            start_time = EDD_find_earliest_start_time(machine_usages, operation.start_time, operation.processing_time)\n",
    "            if check_availability(start_time, operation.processing_time, machine_usages):\n",
    "                if start_time < best_start_time:\n",
    "                    best_start_time = start_time\n",
    "                    selected_machine = machine_usages\n",
    "                    selected_machine_name = machine_name\n",
    "\n",
    "        if selected_machine is None:\n",
    "            # No available machine found; push operation back to recheck later\n",
    "            heapq.heappush(Q, (operation.due_date if operation.due_date is not None else float('inf'), operation.processing_time, operation_id))\n",
    "            # print(f\"Operation {operation.id} not scheduled yet, re-adding to the queue\")\n",
    "            continue\n",
    "\n",
    "        # Schedule the operation\n",
    "        operation.start_time = best_start_time\n",
    "        operation.end_time = operation.start_time + operation.processing_time\n",
    "        selected_machine.append((operation.start_time, operation.end_time))\n",
    "        selected_machine.sort()\n",
    "\n",
    "        # # Debug information\n",
    "        # print(f\"Operation {operation.id}: Scheduled from {operation.start_time} to {operation.end_time} on machine {selected_machine_name} in workcenter {operation.workcenter}\")\n",
    "        # print(f\"Machine {selected_machine_name} in workcenter {operation.workcenter} usage after scheduling operation {operation.id}: {selected_machine}\")\n",
    "\n",
    "        operation.scheduled = True\n",
    "        scheduled_operations.append(operation)\n",
    "\n",
    "        # Update dependencies and add ready operations to the queue\n",
    "        for op_id, op in operations.items():\n",
    "            if not op.scheduled and op_id in unscheduled_dependencies:\n",
    "                for comp_id in op.predecessor_operations:\n",
    "                    if operations[comp_id].scheduled:\n",
    "                        unscheduled_dependencies[op_id] -= 1\n",
    "                if unscheduled_dependencies[op_id] == 0:\n",
    "                    heapq.heappush(Q, (op.due_date if op.due_date is not None else float('inf'), op.processing_time, op_id))\n",
    "                    # print(f\"Operation {op_id} with no remaining dependencies added to the queue\")\n",
    "\n",
    "    # Check if all operations have been scheduled\n",
    "    unscheduled_ops = [op_id for op_id, op in operations.items() if not op.scheduled]\n",
    "    if unscheduled_ops:\n",
    "        # print(f\"Unscheduled operations remaining: {unscheduled_ops}\")\n",
    "        # Attempt to schedule remaining unscheduled operations\n",
    "        for op_id in unscheduled_ops:\n",
    "            operation = operations[op_id]\n",
    "            # Compute start time based on dependencies\n",
    "            if operation.predecessor_operations:\n",
    "                max_end_time = max(\n",
    "                    (operations[comp_id].end_time if operations[comp_id].end_time is not None else -float('inf'))\n",
    "                    for comp_id in operation.predecessor_operations\n",
    "                )\n",
    "                operation.start_time = max_end_time\n",
    "            else:\n",
    "                operation.start_time = 0\n",
    "\n",
    "            # Find the best machine and start time\n",
    "            workcenter = factory[operation.workcenter]\n",
    "            best_start_time = float('inf')\n",
    "            selected_machine = None\n",
    "            selected_machine_name = None\n",
    "            \n",
    "            for machine_name, machine_usages in workcenter.machines.items():\n",
    "                # print(f\"Machine: {machine_name}, Usages: {machine_usages}\")\n",
    "                \n",
    "                # Ensure machine_usages is a list of tuples\n",
    "                if not all(isinstance(interval, tuple) and len(interval) == 2 for interval in machine_usages):\n",
    "                    raise ValueError(f\"Machine usages for {machine_name} in workcenter {operation.workcenter} must be a list of tuples with exactly two values each.\")\n",
    "                    \n",
    "                start_time = EDD_find_earliest_start_time(machine_usages, operation.start_time, operation.processing_time)\n",
    "                if check_availability(start_time, operation.processing_time, machine_usages):\n",
    "                    if start_time < best_start_time:\n",
    "                        best_start_time = start_time\n",
    "                        selected_machine = machine_usages\n",
    "                        selected_machine_name = machine_name\n",
    "\n",
    "            if selected_machine is None:\n",
    "                # print(f\"Operation {operation.id} could not be scheduled\")\n",
    "                continue\n",
    "\n",
    "            # Schedule the operation\n",
    "            operation.start_time = best_start_time\n",
    "            operation.end_time = operation.start_time + operation.processing_time\n",
    "            selected_machine.append((operation.start_time, operation.end_time))\n",
    "            selected_machine.sort()\n",
    "\n",
    "            # # Debug information\n",
    "            # print(f\"Operation {operation.id}: Scheduled from {operation.start_time} to {operation.end_time} on machine {selected_machine_name} in workcenter {operation.workcenter}\")\n",
    "            # print(f\"Machine {selected_machine_name} in workcenter {operation.workcenter} usage after scheduling operation {operation.id}: {selected_machine}\")\n",
    "\n",
    "            operation.scheduled = True\n",
    "            scheduled_operations.append(operation)\n",
    "\n",
    "    return scheduled_operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============\n",
    "#       SA\n",
    "# ==============\n",
    "initial_temperature = 1000\n",
    "cooling_rate = 0.8\n",
    "min_temperature = 1\n",
    "iterations_per_temp = 10\n",
    "\n",
    "def SA_main(df_BOM, df_machine):\n",
    "    # Create an initial schedule\n",
    "    initial_schedule = SA_initial_solution(df_BOM)\n",
    "    # print(\"Initial Schedule:\", initial_schedule)\n",
    "\n",
    "    # Test the revised evaluation function with machine availability\n",
    "    initial_makespan, initial_usage = SA_calculate_makespan(initial_schedule, df_BOM, df_machine)\n",
    "    # print(\"Initial Makespan with Machine Availability:\", initial_makespan)\n",
    "\n",
    "    # Run the simulated annealing algorithm\n",
    "    best_schedule, best_makespan = simulated_annealing(df_BOM, df_machine, initial_schedule, initial_temperature, cooling_rate, min_temperature, iterations_per_temp)\n",
    "    # print(\"Best Schedule:\", best_schedule)\n",
    "    # print(\"Best Makespan:\", best_makespan)\n",
    "\n",
    "    # Generate the Gantt chart for the best schedule\n",
    "    # SA_generate_detailed_gantt_chart(best_schedule, df_BOM, best_makespan, df_machine)\n",
    "    # SA_generate_beautified_gantt_chart(best_schedule, df_BOM, df_machine)\n",
    "\n",
    "    # Export the best schedule to CSV\n",
    "    return SA_format_schedule(best_schedule, df_BOM, df_machine)\n",
    "\n",
    "def SA_initial_solution(df_BOM):\n",
    "    schedule = []\n",
    "    remaining_operations = set(df_BOM['operation'].tolist())\n",
    "    \n",
    "    while remaining_operations:\n",
    "        for op in list(remaining_operations):\n",
    "            predecessors = df_BOM[df_BOM['operation'] == op]['predecessor_operations'].values[0]\n",
    "            if all(pred in schedule for pred in predecessors):\n",
    "                schedule.append(op)\n",
    "                remaining_operations.remove(op)\n",
    "    \n",
    "    return schedule\n",
    "\n",
    "def SA_calculate_makespan(schedule, df_BOM, df_machine):\n",
    "    end_times = {}\n",
    "    machine_availability = {\n",
    "        workcenter: {machine: [0] * df_machine.loc[df_machine['workcenter'] == workcenter, machine].values[0]\n",
    "                     for machine in df_machine.columns if machine != 'workcenter'}\n",
    "        for workcenter in df_machine['workcenter']\n",
    "    }\n",
    "    workcenter_machine_usage = {\n",
    "        workcenter: {machine: [] for machine in df_machine.columns if machine != 'workcenter'}\n",
    "        for workcenter in df_machine['workcenter']\n",
    "    }\n",
    "\n",
    "    for op in schedule:\n",
    "        machine = df_BOM[df_BOM['operation'] == op]['machine'].values[0]\n",
    "        workcenter = df_BOM[df_BOM['operation'] == op]['workcenter'].values[0]\n",
    "        processing_time = df_BOM[df_BOM['operation'] == op]['processing_time'].values[0]\n",
    "        predecessors = df_BOM[df_BOM['operation'] == op]['predecessor_operations'].values[0]\n",
    "\n",
    "        # Calculate the earliest start time considering both predecessors and machine availability\n",
    "        start_time = max([end_times.get(pred, 0) for pred in predecessors], default=0)\n",
    "        \n",
    "        # Find the earliest available machine in the workcenter\n",
    "        earliest_machine_idx = min(range(len(machine_availability[workcenter][machine])), key=lambda x: machine_availability[workcenter][machine][x])\n",
    "        start_time = max(start_time, machine_availability[workcenter][machine][earliest_machine_idx])\n",
    "\n",
    "        # Calculate the end time of the operation\n",
    "        end_time = start_time + processing_time\n",
    "        end_times[op] = end_time\n",
    "\n",
    "        # Update the machine availability and usage\n",
    "        machine_availability[workcenter][machine][earliest_machine_idx] = end_time\n",
    "        workcenter_machine_usage[workcenter][machine].append((start_time, end_time, op, earliest_machine_idx))\n",
    "\n",
    "    return max(end_times.values()), workcenter_machine_usage\n",
    "\n",
    "def SA_check_precedence_constraints(schedule, df_BOM):\n",
    "    operation_positions = {op: idx for idx, op in enumerate(schedule)}\n",
    "    for op in schedule:\n",
    "        predecessors = df_BOM[df_BOM['operation'] == op]['predecessor_operations'].values[0]\n",
    "        if any(operation_positions[pred] >= operation_positions[op] for pred in predecessors):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def SA_generate_neighbor(schedule, df_BOM):\n",
    "    new_schedule = schedule[:]\n",
    "    while True:\n",
    "        idx1, idx2 = random.sample(range(len(schedule)), 2)\n",
    "        new_schedule[idx1], new_schedule[idx2] = new_schedule[idx2], new_schedule[idx1]\n",
    "        if SA_check_precedence_constraints(new_schedule, df_BOM):\n",
    "            break\n",
    "        else:\n",
    "            new_schedule = schedule[:]\n",
    "    return new_schedule\n",
    "\n",
    "def SA_accept_solution(current_makespan, new_makespan, temperature):\n",
    "    if new_makespan < current_makespan:\n",
    "        return True\n",
    "    else:\n",
    "        prob = np.exp((current_makespan - new_makespan) / temperature)\n",
    "        return random.random() < prob\n",
    "\n",
    "def simulated_annealing(df_BOM, df_machine, initial_schedule, initial_temperature, cooling_rate, min_temperature, iterations_per_temp):\n",
    "    current_schedule = initial_schedule\n",
    "    current_makespan, _ = SA_calculate_makespan(current_schedule, df_BOM, df_machine)\n",
    "    best_schedule = current_schedule\n",
    "    best_makespan = current_makespan\n",
    "    temperature = initial_temperature\n",
    "    # print(temperature)\n",
    "    while temperature > min_temperature:\n",
    "        for _ in range(iterations_per_temp):\n",
    "            new_schedule = SA_generate_neighbor(current_schedule, df_BOM)\n",
    "            new_makespan, _ = SA_calculate_makespan(new_schedule, df_BOM, df_machine)\n",
    "            \n",
    "            if SA_check_precedence_constraints(new_schedule, df_BOM) and SA_accept_solution(current_makespan, new_makespan, temperature):\n",
    "                current_schedule = new_schedule\n",
    "                current_makespan = new_makespan\n",
    "                \n",
    "                if new_makespan < best_makespan:\n",
    "                    best_schedule = new_schedule\n",
    "                    best_makespan = new_makespan\n",
    "        # print(temperature)\n",
    "        temperature *= cooling_rate\n",
    "    return best_schedule, best_makespan\n",
    "\n",
    "def SA_generate_detailed_gantt_chart(schedule, df_BOM, total_makespan, df_machine):\n",
    "    _, workcenter_machine_usage = SA_calculate_makespan(schedule, df_BOM, df_machine)\n",
    "\n",
    "    # Generate colors for each machine-workcenter combination\n",
    "    unique_machines = df_BOM['machine'].unique()\n",
    "    unique_workcenters = df_BOM['workcenter'].unique()\n",
    "    color_palette = plt.cm.get_cmap('tab20', len(unique_machines) * len(unique_workcenters))\n",
    "    color_index = 0\n",
    "    colors = {}\n",
    "    for wc in unique_workcenters:\n",
    "        for machine in unique_machines:\n",
    "            colors[(wc, machine)] = color_palette(color_index)\n",
    "            color_index += 1\n",
    "\n",
    "    # Plot the Gantt chart\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "    y_ticks = []\n",
    "    y_labels = []\n",
    "    y_position = 0\n",
    "\n",
    "    for wc in df_machine['workcenter']:\n",
    "        for machine in df_machine.columns:\n",
    "            if machine != 'workcenter':\n",
    "                num_machines = df_machine.loc[df_machine['workcenter'] == wc, machine].values[0]\n",
    "                for machine_idx in range(num_machines):\n",
    "                    if (wc in workcenter_machine_usage) and (machine in workcenter_machine_usage[wc]):\n",
    "                        for (start, end, op, used_machine_idx) in workcenter_machine_usage[wc][machine]:\n",
    "                            if used_machine_idx == machine_idx:\n",
    "                                ax.broken_barh([(start, end - start)], (y_position - 0.4, 0.8), facecolors=(colors[(wc, machine)]))\n",
    "                                ax.text(start, y_position, f\" {op} ({machine}-{machine_idx + 1})\", va='center', ha='left')\n",
    "\n",
    "                    y_ticks.append(y_position)\n",
    "                    y_labels.append(f\"{wc} {machine}-{machine_idx + 1}\")\n",
    "                    y_position += 1\n",
    "\n",
    "    ax.set_yticks(y_ticks)\n",
    "    ax.set_yticklabels(y_labels)\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Machine - Workcenter')\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Ensure the x-axis matches the total makespan\n",
    "    ax.set_xlim(0, total_makespan)\n",
    "\n",
    "    # Create a legend for the color-coded machine and workcenter\n",
    "    legend_patches = [mpatches.Patch(color=colors[(wc, machine)], label=f'{wc} - {machine}')\n",
    "                      for wc in unique_workcenters for machine in unique_machines]\n",
    "    ax.legend(handles=legend_patches, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def SA_generate_beautified_gantt_chart(schedule, df_BOM, df_machine):\n",
    "    schedule_data = []\n",
    "    operation_end_times = {}\n",
    "    machine_availability = {\n",
    "        workcenter: {machine: [0] * df_machine.loc[df_machine['workcenter'] == workcenter, machine].values[0]\n",
    "                     for machine in df_machine.columns if machine != 'workcenter'}\n",
    "        for workcenter in df_machine['workcenter']\n",
    "    }\n",
    "\n",
    "    # Define a light color palette for each workcenter\n",
    "    unique_workcenters = df_BOM['workcenter'].unique()\n",
    "    color_palette = plt.cm.get_cmap('Pastel1', len(unique_workcenters))\n",
    "    workcenter_colors = {workcenter: color_palette(i) for i, workcenter in enumerate(unique_workcenters)}\n",
    "\n",
    "    for op in schedule:\n",
    "        machine = df_BOM[df_BOM['operation'] == op]['machine'].values[0]\n",
    "        workcenter = df_BOM[df_BOM['operation'] == op]['workcenter'].values[0]\n",
    "        processing_time = df_BOM[df_BOM['operation'] == op]['processing_time'].values[0]\n",
    "        predecessors = df_BOM[df_BOM['operation'] == op]['predecessor_operations'].values[0]\n",
    "\n",
    "        # Calculate the earliest start time considering predecessors\n",
    "        start_time = max([operation_end_times.get(pred, 0) for pred in predecessors], default=0)\n",
    "        \n",
    "        # Find the earliest available machine in the workcenter\n",
    "        earliest_machine_idx = min(range(len(machine_availability[workcenter][machine])), key=lambda x: machine_availability[workcenter][machine][x])\n",
    "        start_time = max(start_time, machine_availability[workcenter][machine][earliest_machine_idx])\n",
    "\n",
    "        # Calculate the end time of the operation\n",
    "        end_time = start_time + processing_time\n",
    "        schedule_data.append({\n",
    "            'Operation': op,\n",
    "            'Start': start_time,\n",
    "            'End': end_time,\n",
    "            'Machine': machine,\n",
    "            'Workcenter': workcenter,\n",
    "            'Color': workcenter_colors[workcenter],\n",
    "            'MachineIdx': earliest_machine_idx + 1\n",
    "        })\n",
    "\n",
    "        # Update the availability time for the machine in the workcenter\n",
    "        machine_availability[workcenter][machine][earliest_machine_idx] = end_time\n",
    "        operation_end_times[op] = end_time\n",
    "\n",
    "    # Convert schedule data to DataFrame for plotting\n",
    "    df_schedule = pd.DataFrame(schedule_data)\n",
    "\n",
    "    # Plot the Gantt chart\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "    for idx, row in df_schedule.iterrows():\n",
    "        ax.broken_barh(\n",
    "            [(row['Start'], row['End'] - row['Start'])],\n",
    "            (idx - 0.4, 0.8),\n",
    "            facecolors=(row['Color'])\n",
    "        )\n",
    "        ax.text(\n",
    "            row['Start'] + 0.1,\n",
    "            idx,\n",
    "            f\"{row['Operation']} ({row['Machine']}-{row['MachineIdx']})\",\n",
    "            va='center',\n",
    "            ha='left',\n",
    "            color='black'\n",
    "        )\n",
    "\n",
    "    ax.set_yticks(range(len(df_schedule)))\n",
    "    ax.set_yticklabels(df_schedule['Operation'])\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Operations')\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Ensure the x-axis matches the total makespan\n",
    "    ax.set_xlim(0, df_schedule['End'].max())\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def SA_format_schedule(schedule, df_BOM, df_machine):\n",
    "    max_makespan, workcenter_machine_usage = SA_calculate_makespan(schedule, df_BOM, df_machine)\n",
    "    export_data = []\n",
    "\n",
    "    # Gather utilized machines information\n",
    "    used_machines = set()\n",
    "    for wc in workcenter_machine_usage:\n",
    "        for machine in workcenter_machine_usage[wc]:\n",
    "            for (start, end, op, machine_idx) in workcenter_machine_usage[wc][machine]:\n",
    "                used_machines.add((wc, machine, machine_idx))\n",
    "                export_data.append({\n",
    "                    'Operation': op,\n",
    "                    'Start': start,\n",
    "                    'End': end,\n",
    "                    'Workcenter': wc,\n",
    "                    'Machine': machine,\n",
    "                    'MachineIdx': machine_idx + 1\n",
    "                })\n",
    "\n",
    "\n",
    "\n",
    "    # Add unused machines information\n",
    "    for wc in df_machine['workcenter']:\n",
    "        for machine in df_machine.columns:\n",
    "            if machine != 'workcenter':\n",
    "                num_machines = df_machine.loc[df_machine['workcenter'] == wc, machine].values[0]\n",
    "                for idx in range(num_machines):\n",
    "                    if (wc, machine, idx) not in used_machines:\n",
    "                        export_data.append({\n",
    "                            'Operation': None,\n",
    "                            'Start': None,\n",
    "                            'End': None,\n",
    "                            'Workcenter': wc,\n",
    "                            'Machine': machine,\n",
    "                            'MachineIdx': idx + 1\n",
    "                        })\n",
    "    \n",
    "    return pd.DataFrame(export_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Systematic Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "def print_progress_bar(iteration, total, length=50):\n",
    "    if iteration == 0:\n",
    "        return  # Don't print the progress bar when no progress has been made.\n",
    "    percent = (\"{0:.1f}\").format(100 * (iteration / float(total)))\n",
    "    filled_length = int(length * iteration // total)\n",
    "    bar = '█' * filled_length + '-' * (length - filled_length)\n",
    "    sys.stdout.write(f'\\r|{bar}| {percent}% Complete')\n",
    "    sys.stdout.flush()\n",
    "    if iteration == total:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 69\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# print(EDD_processing_time)\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# SA\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# print(\"SA\")\u001b[39;00m\n\u001b[0;32m     68\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 69\u001b[0m SA_scheduled_operations \u001b[38;5;241m=\u001b[39m \u001b[43mSA_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_BOM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_machine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     71\u001b[0m SA_processing_time \u001b[38;5;241m=\u001b[39m end \u001b[38;5;241m-\u001b[39m start \n",
      "Cell \u001b[1;32mIn[9], line 19\u001b[0m, in \u001b[0;36mSA_main\u001b[1;34m(df_BOM, df_machine)\u001b[0m\n\u001b[0;32m     15\u001b[0m initial_makespan, initial_usage \u001b[38;5;241m=\u001b[39m SA_calculate_makespan(initial_schedule, df_BOM, df_machine)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# print(\"Initial Makespan with Machine Availability:\", initial_makespan)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Run the simulated annealing algorithm\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m best_schedule, best_makespan \u001b[38;5;241m=\u001b[39m \u001b[43msimulated_annealing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_BOM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_machine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_schedule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_temperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcooling_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_temperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations_per_temp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# print(\"Best Schedule:\", best_schedule)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# print(\"Best Makespan:\", best_makespan)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Export the best schedule to CSV\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m SA_format_schedule(best_schedule, df_BOM, df_machine)\n",
      "Cell \u001b[1;32mIn[9], line 113\u001b[0m, in \u001b[0;36msimulated_annealing\u001b[1;34m(df_BOM, df_machine, initial_schedule, initial_temperature, cooling_rate, min_temperature, iterations_per_temp)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m temperature \u001b[38;5;241m>\u001b[39m min_temperature:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations_per_temp):\n\u001b[1;32m--> 113\u001b[0m         new_schedule \u001b[38;5;241m=\u001b[39m \u001b[43mSA_generate_neighbor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_schedule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_BOM\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m         new_makespan, _ \u001b[38;5;241m=\u001b[39m SA_calculate_makespan(new_schedule, df_BOM, df_machine)\n\u001b[0;32m    116\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m SA_check_precedence_constraints(new_schedule, df_BOM) \u001b[38;5;129;01mand\u001b[39;00m SA_accept_solution(current_makespan, new_makespan, temperature):\n",
      "Cell \u001b[1;32mIn[9], line 91\u001b[0m, in \u001b[0;36mSA_generate_neighbor\u001b[1;34m(schedule, df_BOM)\u001b[0m\n\u001b[0;32m     89\u001b[0m idx1, idx2 \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(schedule)), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     90\u001b[0m new_schedule[idx1], new_schedule[idx2] \u001b[38;5;241m=\u001b[39m new_schedule[idx2], new_schedule[idx1]\n\u001b[1;32m---> 91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mSA_check_precedence_constraints\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_schedule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_BOM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[9], line 81\u001b[0m, in \u001b[0;36mSA_check_precedence_constraints\u001b[1;34m(schedule, df_BOM)\u001b[0m\n\u001b[0;32m     79\u001b[0m operation_positions \u001b[38;5;241m=\u001b[39m {op: idx \u001b[38;5;28;01mfor\u001b[39;00m idx, op \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(schedule)}\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m schedule:\n\u001b[1;32m---> 81\u001b[0m     predecessors \u001b[38;5;241m=\u001b[39m \u001b[43mdf_BOM\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_BOM\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moperation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredecessor_operations\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(operation_positions[pred] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m operation_positions[op] \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m predecessors):\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\natha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4081\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4079\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[0;32m   4080\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 4081\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_bool_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4083\u001b[0m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[0;32m   4084\u001b[0m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[0;32m   4085\u001b[0m is_single_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[1;32mc:\\Users\\natha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4143\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   4142\u001b[0m indexer \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 4143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\natha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:4150\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   4139\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   4140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices, axis: Axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m   4141\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4142\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[0;32m   4143\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4148\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   4149\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4150\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4151\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[0;32m   4152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[1;32mc:\\Users\\natha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:4130\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[1;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[0;32m   4125\u001b[0m     \u001b[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[0;32m   4126\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[0;32m   4127\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[0;32m   4128\u001b[0m     )\n\u001b[1;32m-> 4130\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4132\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   4134\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[0;32m   4136\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4137\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\natha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:894\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[0;32m    891\u001b[0m indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[0;32m    893\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m--> 894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\natha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:704\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    701\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(new_blocks, new_axes)\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;66;03m# We can avoid the need to rebuild these\u001b[39;00m\n\u001b[1;32m--> 704\u001b[0m     new_mgr\u001b[38;5;241m.\u001b[39m_blknos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblknos\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    705\u001b[0m     new_mgr\u001b[38;5;241m.\u001b[39m_blklocs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblklocs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    706\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_mgr\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# GENERATING THE FACTORY INFORMATION\n",
    "random.seed(42)\n",
    "n_workcenters, n_machines = 3, 5\n",
    "dict_machine = {}\n",
    "dict_machine[0] = pd.DataFrame({ 'workcenter': [f\"WC{i}\" for i in range(1,n_workcenters+1)] })\n",
    "dict_machine[1] = pd.DataFrame({ 'workcenter': [f\"WC{i}\" for i in range(1,n_workcenters+1)] })\n",
    "dict_machine[2] = pd.DataFrame({ 'workcenter': [f\"WC{i}\" for i in range(1,n_workcenters+1)] })\n",
    "\n",
    "for machine_no in range(1,n_machines+1):\n",
    "    dict_machine[0][f\"M{machine_no}\"] = [random.randint(1,5) for _ in range(1,n_workcenters+1)]\n",
    "    dict_machine[1][f\"M{machine_no}\"] = [random.randint(1,3) for _ in range(1,n_workcenters+1)]\n",
    "    dict_machine[2][f\"M{machine_no}\"] = [random.randint(1,1) for _ in range(1,n_workcenters+1)]\n",
    "\n",
    "\n",
    "files = os.listdir('TestCases') \n",
    "files = [file for file in files if file[-3:] == \"csv\"]\n",
    "total_files = len(files)\n",
    "df_results = pd.DataFrame({\n",
    "    'filename': [None],\n",
    "    'LETSA_time_0': [None],\n",
    "    'LETSA_time_1': [None],\n",
    "    'LETSA_time_2': [None],\n",
    "    'EDD_time_0': [None],\n",
    "    'EDD_time_1': [None],\n",
    "    'EDD_time_2': [None],\n",
    "    'SA_time_0': [None],\n",
    "    'SA_time_1': [None],\n",
    "    'SA_time_2': [None]\n",
    "})\n",
    "\n",
    "folder_path = 'LETSA_testcase'\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "for i, filename in enumerate(files): \n",
    "    df_BOM = pd.read_csv(f\"TestCases//{filename}\")\n",
    "    # print(\"df_BOM\")\n",
    "    # display(df_BOM)\n",
    "    df_BOM['predecessor_operations'] = df_BOM['predecessor_operations'].apply(lambda x: ast.literal_eval(x) if pd.notnull(x) else [])\n",
    "\n",
    "    # LETSA\n",
    "    for j in range(3): \n",
    "        # print(j)\n",
    "        df_machine = dict_machine[j]\n",
    "        # display(df_machine)\n",
    "\n",
    "        # print(\"LETSA\")\n",
    "        start = time.time()\n",
    "        factory = LETSA_load_factory(df_machine)\n",
    "        operations = LETSA_load_operations(df_BOM)\n",
    "        LETSA_scheduled_operations = LETSA_schedule_operations(operations, factory)\n",
    "        end = time.time()\n",
    "        LETSA_processing_time = end - start\n",
    "        # print(LETSA_processing_time)\n",
    "\n",
    "        # EDD\n",
    "        # print(\"EDD\")\n",
    "        start = time.time()\n",
    "        factory = EDD_load_factory(df_machine)\n",
    "        operations = EDD_load_operations(df_BOM)\n",
    "        EDD_scheduled_operations = EDD_schedule_operations(operations, factory)\n",
    "        end = time.time()\n",
    "        EDD_processing_time = end - start\n",
    "        # print(EDD_processing_time)\n",
    "\n",
    "        # SA\n",
    "        # print(\"SA\")\n",
    "        start = time.time()\n",
    "        SA_scheduled_operations = SA_main(df_BOM, df_machine)\n",
    "        end = time.time()\n",
    "        SA_processing_time = end - start \n",
    "        # print(SA_processing_time)\n",
    "\n",
    "        df_results.at[i, f\"LETSA_time_{j}\"] = LETSA_processing_time\n",
    "        df_results.at[i, f\"EDD_time_{j}\"] = EDD_processing_time\n",
    "        df_results.at[i, f\"SA_time_{j}\"] = SA_processing_time\n",
    "\n",
    "    df_results.at[i, \"filename\"] = filename\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
